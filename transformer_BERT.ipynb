{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "#from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import psutil\n",
    "import sys\n",
    "from itertools import islice\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import unicodedata\n",
    "from multiprocess import Pool\n",
    "import pickle\n",
    "import random \n",
    "random.seed(1234)\n",
    "\n",
    "# use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple/minimal implementation of the BERT model (https://arxiv.org/pdf/1810.04805v2.pdf) \n",
    "\n",
    "##### The transformer block and multihead attention layer implementations are based on the Andrej Karpathy GPT youtube tutorial. In this case, we use a transformer encoder block which uses bi-directional context, differing from the transformer decoder in GPT which is unidirectional (achieved via causal masking of attention weights).\n",
    "\n",
    "#### Pre-Training:\n",
    "\n",
    "##### We will train our BERT model on the masked language modeling (MLM) task. The MLM task involves masking out parts of the input sequence and having the model reconstruct those missing parts. By pre-training the model on this task using a large corpus, it learns a strong representation of language (e.g. it learns syntax structure, gains knowledge about the world and different entities, word semantics and sentiment) which can then be trasferred into many different downstream language tasks with some additional finetuning. The learning process is made even more robust by masking out randomly selected tokens from the input sequence which don't necessarily have to be in a contiguous chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, block_size, embedding_dim, total_head_size, num_heads, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        assert total_head_size % num_heads == 0, \"head_size needs to be integer multiple of num_heads\"\n",
    "\n",
    "        self.block_size = block_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.total_head_size = total_head_size \n",
    "        self.head_size = total_head_size // num_heads \n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # define parameters\n",
    "        self.key = nn.Linear(embedding_dim, self.total_head_size, bias=False)\n",
    "        self.query = nn.Linear(embedding_dim, self.total_head_size, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, self.total_head_size, bias=False)\n",
    "        self.attn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # we also need to apply a linear projection to make the output residual the same dimension as the input\n",
    "        self.proj = nn.Linear(total_head_size, embedding_dim) \n",
    "        self.output_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "\n",
    "    # define forward pass, input shape: (B,T,C) where B=batch size, T=block_size, C=embedding_dim\n",
    "    # the attn_mask is a mask that can be used for masking out the attention weights for padding tokens \n",
    "    def forward(self, x, attn_mask):\n",
    "        B, T, C = x.shape\n",
    "        #print(f\"B = {B}, T={T}, C={C}\")\n",
    "        k = self.key(x) # (B,T,H) where H is the total_head_size\n",
    "        q = self.query(x) # (B,T,H)\n",
    "        v = self.value(x) # (B,T,H)\n",
    "\n",
    "        # reshape (B,T,H) --> (B,T,n,h), where n=num_heads and h=head_size and H=n*h\n",
    "        k = k.view(B,T,self.num_heads,self.head_size) \n",
    "        q = q.view(B,T,self.num_heads,self.head_size) \n",
    "        v = v.view(B,T,self.num_heads,self.head_size) \n",
    "\n",
    "        # now we transpose so that the num_heads is the second dimension followed by T,h\n",
    "        # this allows us to batch matrix mutliply for all heads simulataneously to compute their attention weights\n",
    "        # (B,T,n,h) --> (B,n,T,h) \n",
    "        k = k.transpose(1,2) \n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "\n",
    "        # compute attention scores manually (slower)\n",
    "        W = q @ k.transpose(-2,-1)  / math.sqrt(self.head_size) # (B,n,T,T)\n",
    "        attn_mask = attn_mask.view(B,1,1,T)        \n",
    "        #print(f\"W shape= {W.shape}, attn_mask shape = {attn_mask.shape}\")\n",
    "        W = W.masked_fill(attn_mask == 0, float('-inf')) \n",
    "        W = F.softmax(W, dim=-1)\n",
    "        # apply dropout to attention weights\n",
    "        W = self.attn_dropout(W)\n",
    "        out = W @ v # (B,n,T,h)\n",
    "        \n",
    "\n",
    "        # use pytorch built-in function for faster computation of attention scores (set the 'is_causal' parameter for applying causal masking)\n",
    "        #out = F.scaled_dot_product_attention(q,k,v,attn_mask=attn_mask.bool(),dropout_p=self.dropout_rate if self.training else 0,is_causal=False)\n",
    "\n",
    "        # we can transpose the output from (B,n,T,h) --> (B,T,n,h)\n",
    "        # since the last two dimensions of the transposed tensor are non-contiguous, we apply \n",
    "        # contiguous() which return a contiguous tensor\n",
    "        out = out.transpose(1,2).contiguous()\n",
    "\n",
    "        # finally we collapse the last two dimensions to get the concatenated output, (B,T,n,h) --> (B,T,n*h) \n",
    "        out = out.view(B,T,self.total_head_size)\n",
    "\n",
    "        # now we project the concatenated output so that it has the same dimensions as the multihead attention layer input\n",
    "        # (we need to add it with the input because of the residual connection, so need to be same size) \n",
    "        out = self.proj(out) # (B,T,C) \n",
    "\n",
    "        # apply dropout\n",
    "        out = self.output_dropout(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "# a simple mlp \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        # we add extra computations by growing out the feed-forward hidden size by a factor of 4\n",
    "        # we also add an extra linear layer at the end to project the residual back to same dimensions as input\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 4*embedding_dim),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*embedding_dim, embedding_dim), \n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "    \n",
    "    # in the forward pass, concatenate the outputs from all the attention heads\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "# transformer encoder block with residual connection and layer norm\n",
    "# Note: the original transformer uses post layer norms, here we use pre layer norms, i.e. layer norm is applied at the input\n",
    "# instead of the output, this typically leads to better results in terms of training convergence speed and gradient scaling \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, block_size, embedding_dim, head_size, num_heads, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.sa = MultiHeadAttention(block_size, embedding_dim, head_size, num_heads, dropout_rate) # multi-head attention layer \n",
    "        self.ff = FeedForward(embedding_dim, dropout_rate)   # feed-forward layer\n",
    "        self.ln1 = nn.LayerNorm(embedding_dim) # layer norm at input of multi-head attention\n",
    "        self.ln2 = nn.LayerNorm(embedding_dim) # layer norm at input of feed-forward\n",
    "\n",
    "    # in the forward pass, concatenate the outputs from all the attention heads\n",
    "    def forward(self, x, attn_mask):\n",
    "        # residual connection between input and multi-head attention output (also note that we're doing a pre-layer norm, i.e. layer norm at the input of the multi-head attention)\n",
    "        x = x + self.sa(self.ln1(x), attn_mask)\n",
    "        # residual connection between multi-head attention output and feed-forward output (also note that we're doing a pre-layer norm, i.e. layer norm at the input of the feed-forward)\n",
    "        x = x + self.ff(self.ln2(x)) \n",
    "        return x\n",
    "    \n",
    "\n",
    "# BERT model with multiple transformer blocks \n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, embedding_dim, head_size, num_heads, num_blocks, pad_token_id, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size        # block_size is just the input sequence length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.head_size = head_size\n",
    "        self.hum_heads = num_heads\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        '''\n",
    "        Define model parameters\n",
    "        '''\n",
    "        # token embedding layer \n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_token_id) # shape: (vocab_size,C)\n",
    "        # position embedding layer\n",
    "        self.pos_embedding = nn.Embedding(block_size, embedding_dim) # shape: (T,C)\n",
    "        # segment embedding layer (disabled for now)\n",
    "        #self.segment_embedding = nn.Embedding(2, embedding_dim)\n",
    "\n",
    "        # stack of transformer blocks\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(block_size, embedding_dim, head_size, num_heads, dropout_rate) for _ in range(num_blocks)])\n",
    "\n",
    "        # pooling transformation of CLS token (for downstream tasks requiring full sentence hidden representation)\n",
    "        #self.pooling_linear = nn.Linear(embedding_dim, embedding_dim) # shape: (C,C)\n",
    "        #self.pooling_activation_fn = nn.Tanh()\n",
    "\n",
    "        # output layer\n",
    "        self.ln = nn.LayerNorm(embedding_dim)\n",
    "        self.output_linear = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        # store position indices inside a buffer for fast access when computing position embeddings\n",
    "        position_idx = torch.arange(block_size, device=device).unsqueeze(0)\n",
    "        self.register_buffer('position_idx', position_idx)\n",
    "\n",
    "\n",
    "        # forward pass takes in a batch of input token sequences idx of shape (B,T) and corresponding targets of shape (B,T)\n",
    "    def forward(self, idx, attn_mask, segment_idx=None):\n",
    "        B, T = idx.shape\n",
    "        # get token embeddings\n",
    "        token_embeds = self.token_embedding(idx) # (B,T,C)\n",
    "        # add positional encoding\n",
    "        pos_embeds = self.pos_embedding(self.position_idx[:,:T]) # (T,C) \n",
    "        \n",
    "        # add sentence segment embedding (disabled for now)\n",
    "        # segment_embeds = self.segment_embedding(segment_idx) # segment_idx is an integer tensor of shape (B,T) and has 0's at positions corresponding to \n",
    "        \n",
    "        # the first sentence and 1's at positions corresponding to the second sentence \n",
    "        x = token_embeds + pos_embeds # (B,T,C)\n",
    "        # pass through transformer blocks to get encoding\n",
    "        for block in self.blocks:\n",
    "            x = block(x, attn_mask) # (B,T,C)\n",
    "    \n",
    "        # get CLS token encoding and apply pooling transform\n",
    "        #cls_encoding = x[:,0] # (B,C)\n",
    "        #pooled_cls_encoding = self.pooling_activation_fn(self.pooling_linear(cls_encoding)) # (B,C)\n",
    "\n",
    "        # apply final layers norm\n",
    "        x = self.ln(x)\n",
    "\n",
    "        # compute output logits\n",
    "        logits = self.output_linear(self.dropout(x))\n",
    "\n",
    "        return logits \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Wikipedia Dataset (contains multiple languages..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load the simple English Wikipedia dataset\n",
    "wiki_dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
    "train_dataset = wiki_dataset['train']\n",
    "documents = train_dataset[:]['text']\n",
    "\n",
    "\n",
    "# split each document into list of sentences, aggregate all sentences inside a single list\n",
    "def extract_sentences(document):\n",
    "    return document.replace('\\n\\n', '\\n').split('\\n')\n",
    "\n",
    "with Pool() as pool:\n",
    "    all_sentences = []\n",
    "    for result in tqdm(pool.imap(extract_sentences, documents), total=len(documents)):\n",
    "        all_sentences.append(result)\n",
    "text = [sentence for document_sentences in all_sentences for sentence in document_sentences]\n",
    "\n",
    "print(f\"Total number of sentences: {len(text)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BookCorpus Dataset. For simplicity, we will only use the first 2M sentences from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in reduced corpus: 8000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# load the books corpus dataset from file\n",
    "dataset = Dataset.from_file('book_corpus_dataset/archive/train/dataset.arrow')\n",
    "\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "# check how many sentences are in the dataset\n",
    "print(len(dataset))\n",
    "\n",
    "# show some sentences from the dataset\n",
    "print(dataset[:10]['text'])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# get chunk of 10M sentences\n",
    "chunk = dataset[:10000000]['text']\n",
    "\n",
    "# size in Mb\n",
    "sys.getsizeof(chunk)/1024**2\n",
    "\n",
    "# save it to a txt file\n",
    "with open('bookcorpus_small.txt', 'w') as output:\n",
    "    for sent in chunk:\n",
    "        output.write(f\"{sent}\\n\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def read_first_n_lines(n):\n",
    "    with open(\"bookcorpus_small.txt\", 'r') as file:\n",
    "        return list(islice(file, n))\n",
    "    \n",
    "# read in 2000000 sentences from the txt file\n",
    "text = read_first_n_lines(8000000)\n",
    "text = [line.strip() for line in text]\n",
    "print(f\"Number of sentences in reduced corpus: {len(text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 1229.03 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a bit of preprocessing remove sections that are not relevant for language modeling, such as isbn numbers, URLs, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = []\n",
    "for s in text:\n",
    "    if \"http\" in s or \"isbn\" in s or \"@\" in s or \"^\" in s or \"#\" in s or \"~\" in s or \">\" in s or \"<\" in s or \"{\" in s or \"}\" in s or \"all rights reserved\" in s:\n",
    "        continue\n",
    "    else:\n",
    "        text_clean.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7993754\n"
     ]
    }
   ],
   "source": [
    "print(len(text_clean))\n",
    "text = text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordPiece Tokenizer Algorithm Implementation (https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretokenize the corpus into words and get unigram counts, we will only use the first sentence as an example\n",
    "word_freqs = defaultdict(int)\n",
    "for s in text:\n",
    "    words = s.split()\n",
    "    for word in words:\n",
    "        word_freqs[word] += 1\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'the': 2,\n",
       "             'half-ling': 1,\n",
       "             'book': 1,\n",
       "             'one': 1,\n",
       "             'in': 1,\n",
       "             'fall': 1,\n",
       "             'of': 1,\n",
       "             'igneeria': 1,\n",
       "             'series': 1,\n",
       "             'kaylee': 2,\n",
       "             'soderburg': 2,\n",
       "             'copyright': 1,\n",
       "             '2013': 1,\n",
       "             'all': 1,\n",
       "             'rights': 1,\n",
       "             'reserved': 1,\n",
       "             '.': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the WordPiece vocabulary. This contains all the unique first letters of every word in the corpus and all other letters that appear in words prefixed by '##'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['##-', '##0', '##1', '##3', '##a', '##b', '##d', '##e', '##f', '##g', '##h', '##i', '##k', '##l', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##y', '.', '2', '[CLS]', '[MASK]', '[PAD]', '[SEP]', '[UNK]', 'a', 'b', 'c', 'f', 'h', 'i', 'k', 'o', 'r', 's', 't']\n"
     ]
    }
   ],
   "source": [
    "# initialize WordPiece vocabulary\n",
    "vocab = []\n",
    "for word in word_freqs.keys():\n",
    "    if word[0] not in vocab:\n",
    "        vocab.append(word[0])\n",
    "    for letter in word[1:]:\n",
    "        prefixed = '##' + letter\n",
    "        if prefixed not in vocab:\n",
    "            vocab.append(prefixed)\n",
    "\n",
    "# now add the special tokens\n",
    "vocab = vocab + [\"[PAD]\", \"[CLS]\", \"[UNK]\", \"[MASK]\", \"[SEP]\"]\n",
    "\n",
    "vocab = sorted(vocab)         \n",
    "print(vocab) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split every unique word in corpus into characters and prefix the characters which are not the first with '##'\\\n",
    "e.g. 'word' --> 'w', '##o', '##r', '##d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': ['t', '##h', '##e'],\n",
       " 'half-ling': ['h', '##a', '##l', '##f', '##-', '##l', '##i', '##n', '##g'],\n",
       " 'book': ['b', '##o', '##o', '##k'],\n",
       " 'one': ['o', '##n', '##e'],\n",
       " 'in': ['i', '##n'],\n",
       " 'fall': ['f', '##a', '##l', '##l'],\n",
       " 'of': ['o', '##f'],\n",
       " 'igneeria': ['i', '##g', '##n', '##e', '##e', '##r', '##i', '##a'],\n",
       " 'series': ['s', '##e', '##r', '##i', '##e', '##s'],\n",
       " 'kaylee': ['k', '##a', '##y', '##l', '##e', '##e'],\n",
       " 'soderburg': ['s', '##o', '##d', '##e', '##r', '##b', '##u', '##r', '##g'],\n",
       " 'copyright': ['c', '##o', '##p', '##y', '##r', '##i', '##g', '##h', '##t'],\n",
       " '2013': ['2', '##0', '##1', '##3'],\n",
       " 'all': ['a', '##l', '##l'],\n",
       " 'rights': ['r', '##i', '##g', '##h', '##t', '##s'],\n",
       " 'reserved': ['r', '##e', '##s', '##e', '##r', '##v', '##e', '##d'],\n",
       " '.': ['.']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = {word: [c if i==0 else f\"##{c}\" for i,c in enumerate(word)] for word in word_freqs.keys()}\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will iteratively merge pairs of these splits into subword tokens. To select which pair to merge, we compute a score for all observed pairs as follows:\n",
    "\n",
    "$score(c1,c2) = \\frac{freq(c1,c2)}{freq(c1) * freq(c2)}$\n",
    "\n",
    "where c1 and c2 are a pair of splits, freq(c1,c2) is the count of how many times c1,c2 co-occur in the corpus and freq(c) is the count of how many times we observe c. This merger algorithm trherefore prioritizes merging splits which appear together frequently but appear separately more rarely.\n",
    "\n",
    "\n",
    "For example, \n",
    "\n",
    "freq('t', '##h') = 2 (observed in the word 'the':2) and \n",
    "\n",
    "freq('t') = 2 (observed in the word 'the':2)\n",
    "\n",
    "freq('##h') = 4 (observed in words 'the':2, 'copyright':1,'rights':1)  \n",
    "\n",
    "score('t', '##h') = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing pair scores\n",
    "def compute_pair_scores(splits):\n",
    "    letter_freqs = defaultdict(int)\n",
    "    pair_freqs = defaultdict(int)\n",
    "\n",
    "    for word,freq in word_freqs.items():            \n",
    "        split = splits[word]\n",
    "        # if word only contains one split\n",
    "        if len(split) == 1:\n",
    "            letter_freqs[split[0]] += freq\n",
    "            continue\n",
    "        \n",
    "        # count up every individual split and adjacent pair of splits \n",
    "        for i in range(len(split)-1):\n",
    "            pair = (split[i], split[i+1])\n",
    "            letter_freqs[split[i]] += freq\n",
    "            pair_freqs[pair] += freq\n",
    "        letter_freqs[split[-1]] += freq\n",
    "\n",
    "    scores = {pair: freq/(letter_freqs[pair[0]]*letter_freqs[pair[1]]) for pair,freq in pair_freqs.items()}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('t', '##h'): 0.25, ('##h', '##e'): 0.03125, ('h', '##a'): 0.2, ('##a', '##l'): 0.05, ('##l', '##f'): 0.0625, ('##f', '##-'): 0.5, ('##-', '##l'): 0.125, ('##l', '##i'): 0.025, ('##i', '##n'): 0.05, ('##n', '##g'): 0.041666666666666664, ('b', '##o'): 0.2, ('##o', '##o'): 0.04, ('##o', '##k'): 0.2, ('o', '##n'): 0.125, ('##n', '##e'): 0.03125, ('i', '##n'): 0.125, ('f', '##a'): 0.2, ('##l', '##l'): 0.03125, ('o', '##f'): 0.25, ('i', '##g'): 0.08333333333333333, ('##g', '##n'): 0.041666666666666664, ('##e', '##e'): 0.01171875, ('##e', '##r'): 0.0390625, ('##r', '##i'): 0.075, ('##i', '##a'): 0.04, ('s', '##e'): 0.020833333333333332, ('##i', '##e'): 0.0125, ('##e', '##s'): 0.041666666666666664, ('k', '##a'): 0.2, ('##a', '##y'): 0.13333333333333333, ('##y', '##l'): 0.08333333333333333, ('##l', '##e'): 0.015625, ('s', '##o'): 0.13333333333333333, ('##o', '##d'): 0.13333333333333333, ('##d', '##e'): 0.041666666666666664, ('##r', '##b'): 0.125, ('##b', '##u'): 0.5, ('##u', '##r'): 0.125, ('##r', '##g'): 0.041666666666666664, ('c', '##o'): 0.2, ('##o', '##p'): 0.2, ('##p', '##y'): 0.3333333333333333, ('##y', '##r'): 0.041666666666666664, ('##i', '##g'): 0.06666666666666667, ('##g', '##h'): 0.08333333333333333, ('##h', '##t'): 0.25, ('2', '##0'): 1.0, ('##0', '##1'): 1.0, ('##1', '##3'): 1.0, ('a', '##l'): 0.125, ('r', '##i'): 0.1, ('##t', '##s'): 0.16666666666666666, ('r', '##e'): 0.03125, ('##s', '##e'): 0.020833333333333332, ('##r', '##v'): 0.125, ('##v', '##e'): 0.0625, ('##e', '##d'): 0.020833333333333332}\n",
      "Pair with largest score:  ('2', '##0')\n"
     ]
    }
   ],
   "source": [
    "pair_scores = compute_pair_scores(splits)\n",
    "print(pair_scores)\n",
    "\n",
    "# get pair with largest score (ties broken by picking first occurance of largest value)\n",
    "max_score_pair = max(pair_scores, key = lambda x: pair_scores[x])\n",
    "print(\"Pair with largest score: \", max_score_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge these two splits into a new subword token and add the subword to our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['##-', '##0', '##1', '##3', '##a', '##b', '##d', '##e', '##f', '##g', '##h', '##i', '##k', '##l', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##y', '.', '2', '[CLS]', '[MASK]', '[PAD]', '[SEP]', '[UNK]', 'a', 'b', 'c', 'f', 'h', 'i', 'k', 'o', 'r', 's', 't', '20']\n"
     ]
    }
   ],
   "source": [
    "subword = max_score_pair[0] + max_score_pair[1].lstrip('#')\n",
    "vocab.append(subword)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(c1, c2, splits):\n",
    "    for word in word_freqs:\n",
    "        split = splits[word]\n",
    "        if len(split) > 1:\n",
    "            i = 0\n",
    "            while i < len(split)-1:\n",
    "                if split[i] == c1 and split[i+1] == c2:\n",
    "                    merged = c1 + c2.lstrip('#')\n",
    "                    split = split[:i] + [merged] + split[i+2:]\n",
    "                else:\n",
    "                    i += 1\n",
    "                splits[word] = split\n",
    "\n",
    "    return splits                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': ['t', '##h', '##e'],\n",
       " 'half-ling': ['h', '##a', '##l', '##f', '##-', '##l', '##i', '##n', '##g'],\n",
       " 'book': ['b', '##o', '##o', '##k'],\n",
       " 'one': ['o', '##n', '##e'],\n",
       " 'in': ['i', '##n'],\n",
       " 'fall': ['f', '##a', '##l', '##l'],\n",
       " 'of': ['o', '##f'],\n",
       " 'igneeria': ['i', '##g', '##n', '##e', '##e', '##r', '##i', '##a'],\n",
       " 'series': ['s', '##e', '##r', '##i', '##e', '##s'],\n",
       " 'kaylee': ['k', '##a', '##y', '##l', '##e', '##e'],\n",
       " 'soderburg': ['s', '##o', '##d', '##e', '##r', '##b', '##u', '##r', '##g'],\n",
       " 'copyright': ['c', '##o', '##p', '##y', '##r', '##i', '##g', '##h', '##t'],\n",
       " '2013': ['20', '##1', '##3'],\n",
       " 'all': ['a', '##l', '##l'],\n",
       " 'rights': ['r', '##i', '##g', '##h', '##t', '##s'],\n",
       " 'reserved': ['r', '##e', '##s', '##e', '##r', '##v', '##e', '##d'],\n",
       " '.': ['.']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = merge_pair(max_score_pair[0], max_score_pair[1], splits)\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep merging iteratively until we have reahed some maximum vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 50\n",
    "\n",
    "while len(vocab) < max_vocab_size:\n",
    "    # compute all pair scores\n",
    "    pair_scores = compute_pair_scores(splits)\n",
    "    # get pair with largest score (ties broken by picking first occurance of largest value)\n",
    "    max_score_pair = max(pair_scores, key = lambda x: pair_scores[x])\n",
    "    # add new subword to vacabulary\n",
    "    subword = max_score_pair[0] + max_score_pair[1].lstrip('#')\n",
    "    vocab.append(subword)\n",
    "    # update splits \n",
    "    splits = merge_pair(*max_score_pair, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['##-', '##0', '##1', '##3', '##a', '##b', '##d', '##e', '##f', '##g', '##h', '##i', '##k', '##l', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##y', '.', '2', '[CLS]', '[MASK]', '[PAD]', '[SEP]', '[UNK]', 'a', 'b', 'c', 'f', 'h', 'i', 'k', 'o', 'r', 's', 't', '20', '201', '2013', '##f-', 'of', '##bu', '##py', 'th', '##ht']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we tokenize a given word into the learned subwords. To tokenize a word, we find the longest matching subword starting from the first character and we split the word. Then we repeat the process from the second half. If we reach the fiunal character and haven't found a matching subword from the vocabulary, then we declare the entire word as '[UNK]' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_word(word):\n",
    "    tokens = []\n",
    "    while len(word) > 0:\n",
    "        i = len(word)    \n",
    "        # find longest mactching subword subword\n",
    "        while i > 0 and word[:i] not in vocab:\n",
    "            i -= 1\n",
    "        if i == 0:\n",
    "            # no match found\n",
    "            return [\"[UNK]\"]\n",
    "        # found longest subword\n",
    "        tokens.append(word[:i])\n",
    "        word = word[i:]\n",
    "        # add prefix\n",
    "        if len(word) > 0:\n",
    "            word = f\"##{word}\"\n",
    "    return tokens            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', '##a', '##bu', '##l', '##o', '##u', '##s']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_word(\"fabulous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All together, the WordPiece vocab generator can be implemented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPieceTokenizer():\n",
    "    def __init__(self):\n",
    "        self.vocab = []\n",
    "        self.word2int = {}\n",
    "        self.int2word = {}\n",
    "        # special tokens\n",
    "        self.pad_token = \"[PAD]\"\n",
    "        self.mask_token = \"[MASK]\"\n",
    "        self.unk_token = \"[UNK]\"\n",
    "        self.cls_token = \"[CLS]\"\n",
    "        self.sep_token = \"[SEP]\"\n",
    "        \n",
    "        self.invalid_chars = ('*', '~', '_', '^', '`', '+', '\\\\', '[', ']', '<', '>')\n",
    "        self.max_vocab_size = None\n",
    "        \n",
    "\n",
    "    def mask_token_id(self):\n",
    "        return self.word2int[self.mask_token]\n",
    "\n",
    "    def pad_token_id(self):\n",
    "        return self.word2int[self.pad_token]\n",
    "\n",
    "    def cls_token_id(self):\n",
    "        return self.word2int[self.cls_token]\n",
    "\n",
    "    def unk_token_id(self):\n",
    "        return self.word2int[self.unk_token]\n",
    "\n",
    "    def sep_token_id(self):\n",
    "        return self.word2int[self.sep_token]\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def clean_sentence(self, s):\n",
    "        # removes all control characters and invalid characters, replaces multiple adjacent whitespace with single whitespace\n",
    "    \n",
    "        #s = \"\".join(ch for ch in s if unicodedata.category(ch)[0] != 'C' and ch not in self.invalid_chars) \n",
    "        #s = \" \".join(s.split())\n",
    "        \n",
    "        # remove all non-letter characters\n",
    "        s = \"\".join(ch for ch in s if unicodedata.category(ch)[0]=='L' or unicodedata.category(ch)=='Zs') \n",
    "        s = \" \".join(s.split())\n",
    "        return s\n",
    "\n",
    "    # generates wordpiece vocabulary of subwords from a given corpus\n",
    "    # the input corpus is a list of sentences\n",
    "    def generate_vocab(self, corpus, max_vocab_size):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        # pretokenize the corpus into words and get unigram counts, we will only use the first sentence as an example\n",
    "        word_freqs = defaultdict(int)\n",
    "        for s in corpus:\n",
    "            s = self.clean_sentence(s)\n",
    "            words = s.split()\n",
    "            for word in words:\n",
    "                word_freqs[word] += 1\n",
    "        \n",
    "        # initialize WordPiece vocabulary\n",
    "        for word in word_freqs.keys():\n",
    "            if word[0] not in self.vocab:\n",
    "                self.vocab.append(word[0])\n",
    "            for letter in word[1:]:\n",
    "                prefixed = '##' + letter\n",
    "                if prefixed not in self.vocab:\n",
    "                    self.vocab.append(prefixed)\n",
    "\n",
    "        # now add special tokens\n",
    "        self.vocab = self.vocab + [self.pad_token, self.cls_token, self.unk_token, self.mask_token, self.sep_token]\n",
    "\n",
    "        # generate splits\n",
    "        splits = {word: [c if i==0 else f\"##{c}\" for i,c in enumerate(word)] for word in word_freqs.keys()}\n",
    "        \n",
    "        # function for computing pair scores\n",
    "        def compute_pair_scores(splits):\n",
    "            letter_freqs = defaultdict(int)\n",
    "            pair_freqs = defaultdict(int)\n",
    "\n",
    "            for word,freq in word_freqs.items():            \n",
    "                split = splits[word]\n",
    "                # if word only contains one split\n",
    "                if len(split) == 1:\n",
    "                    letter_freqs[split[0]] += freq\n",
    "                    continue\n",
    "                \n",
    "                # count up every individual split and adjacent pair of splits \n",
    "                for i in range(len(split)-1):\n",
    "                    pair = (split[i], split[i+1])\n",
    "                    letter_freqs[split[i]] += freq\n",
    "                    pair_freqs[pair] += freq\n",
    "                letter_freqs[split[-1]] += freq\n",
    "\n",
    "            scores = {pair: freq/(letter_freqs[pair[0]]*letter_freqs[pair[1]]) for pair,freq in pair_freqs.items()}\n",
    "            return scores\n",
    "        \n",
    "        # function for merging a pair of splits    \n",
    "        def merge_pair(c1, c2, splits):\n",
    "            for word in word_freqs:\n",
    "                split = splits[word]\n",
    "                if len(split) > 1:\n",
    "                    i = 0\n",
    "                    while i < len(split)-1:\n",
    "                        if split[i] == c1 and split[i+1] == c2:\n",
    "                            merged = c1 + c2.lstrip('#')\n",
    "                            split = split[:i] + [merged] + split[i+2:]\n",
    "                        else:\n",
    "                            i += 1\n",
    "                        splits[word] = split\n",
    "\n",
    "            return splits    \n",
    "        \n",
    "        # generate the subword vocabulary\n",
    "        pbar = tqdm(total=max_vocab_size, desc=\"Building vocab. Current vocab_size --> \")\n",
    "        pbar.update(len(self.vocab))\n",
    "\n",
    "        while len(self.vocab) < max_vocab_size:\n",
    "            # compute all pair scores\n",
    "            pair_scores = compute_pair_scores(splits)\n",
    "            # get pairs with largest score \n",
    "            max_score = max(pair_scores.values())\n",
    "            max_score_pairs = [pair for pair, score in pair_scores.items() if score== max_score]\n",
    "            # randomly break ties\n",
    "            max_score_pair = random.choice(max_score_pairs)\n",
    "            # add new subword to vacabulary\n",
    "            subword = max_score_pair[0] + max_score_pair[1].lstrip('#')\n",
    "            self.vocab.append(subword)\n",
    "            # update splits \n",
    "            splits = merge_pair(*max_score_pair, splits)\n",
    "            pbar.update(1)\n",
    "            \n",
    "        self.vocab = sorted(set(self.vocab))\n",
    "        self.word2int = {word:i for i,word in enumerate(self.vocab)}\n",
    "        self.int2word = {i:word for i,word in enumerate(self.vocab)}\n",
    "\n",
    "\n",
    "    def encode_sentence(self, s):\n",
    "        # first clean the sentence\n",
    "        s = self.clean_sentence(s)\n",
    "        # tokenize the sentence into subword sequence\n",
    "        subword_tokens = self.tokenize_sentence(s)\n",
    "        # convert to token indices\n",
    "        indices = [self.word2int[t] for t in subword_tokens]\n",
    "        return indices\n",
    "\n",
    "    # encode sentence into subword token indices\n",
    "    def encode(self, sentences):\n",
    "        encoded_sentences = []\n",
    "        with Pool() as pool:\n",
    "            # Note: since we're using map instead of imap, order of encoded sequences will differ from order of original sequences\n",
    "            for result in tqdm(pool.map(self.encode_sentence, sentences), total=len(sentences), desc=\"Encoding sequences.\"):\n",
    "                encoded_sentences.append(result)\n",
    "        return encoded_sentences\n",
    "\n",
    "\n",
    "    def decode_indices(self, indices):\n",
    "        # first cnvert indices to subword tokens\n",
    "        subwords = [self.int2word[ix] for ix in indices]\n",
    "        # merge subwords\n",
    "        i = 0\n",
    "        while i < len(subwords)-1:\n",
    "            a = subwords[i]\n",
    "            b = subwords[i+1]\n",
    "            if len(b) == 1:\n",
    "                i += 1  \n",
    "                continue\n",
    "            if b[:2]==\"##\":\n",
    "                subwords = subwords[:i] + [a+b.lstrip('#')] + subwords[i+2:]\n",
    "            else:       \n",
    "                i += 1    \n",
    "        s = \" \".join(subwords)\n",
    "        return s\n",
    "\n",
    "\n",
    "    # decode subword token index sequences back to sentences\n",
    "    def decode(self, idx):\n",
    "        sentences = []\n",
    "        with Pool() as pool:\n",
    "            for result in tqdm(pool.imap(self.decode_indices, idx), total=len(idx), desc=\"Decoding sequences.\"):\n",
    "                sentences.append(result)    \n",
    "        return sentences\n",
    "\n",
    "\n",
    "    def tokenize_sentence(self, sent):\n",
    "        tokens = []\n",
    "        # split the sentence into words \n",
    "        # make sure to convert all characters to lower case because our vocabulary does not contain\n",
    "        # upper case letters\n",
    "        words = sent.lower().split()\n",
    "        # tokenize each word\n",
    "        for word in words:\n",
    "            tokens = tokens + self.tokenize_word(word)\n",
    "        return tokens\n",
    "\n",
    "    def tokenize_word(self, word):\n",
    "        tokens = []\n",
    "        while len(word) > 0:\n",
    "            i = len(word)    \n",
    "            # find longest mactching subword subword\n",
    "            while i > 0 and word[:i] not in self.vocab:\n",
    "                i -= 1\n",
    "            if i == 0:\n",
    "                # no match found\n",
    "                return [self.unk_token]\n",
    "            # found longest subword\n",
    "            tokens.append(word[:i])\n",
    "            word = word[i:]\n",
    "            # add prefix\n",
    "            if len(word) > 0:\n",
    "                word = f\"##{word}\"\n",
    "        return tokens          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tokenizer object\n",
    "tokenizer = WordPieceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocab. Current vocab_size --> : 100%|██████████| 8192/8192 [1:32:49<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['##a', '##aaaaaaaaaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaaaaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaaaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaaaauughh', '##aaaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaaarrrrrrrgggghhhhhhhh', '##aaaaaaauughh', '##aaaaaagggggggggggghhhhhhhhhhhh', '##aaaaaarrrrrrrggggggggggghhh', '##aaaaaarrrrrrrgggghhhhhhhh', '##aaaaaauughh', '##aaaaagggggggggggghhhhhhhhhhhh', '##aaaaaggggggghhhhhhhhh', '##aaaaagggggghhhhhh', '##aaaaarrrrggggggggghhhhhh', '##aaaaarrrrggggghhhhhhh', '##aaaaarrrrgggghhhhh', '##aaaaarrrrrrrggggggggggghhh', '##aaaaarrrrrrrgggghhhhhhhh', '##aaaaauughh', '##aaaagggggggggggghhhhhhhhhhhh', '##aaaaggggggghhhhhhhhh', '##aaaagggggghhhhhh', '##aaaaggghhh', '##aaaagghh', '##aaaagongongonaarggg', '##aaaarrrggghhhhhhh', '##aaaarrrrggggggggghhhhhh', '##aaaarrrrgggggghhhhhhhhh', '##aaaarrrrggggghhhhhhh', '##aaaarrrrgggghhhhh', '##aaaarrrrrgggghhhhhh', '##aaaarrrrrrrggggggggggghhh', '##aaaarrrrrrrggggggghhhhhhhh', '##aaaarrrrrrrgggghhhhhhhh', '##aaaauughh', '##aaagggggggggggghhhhhhhhhhhh', '##aaaggggggghhhhhhhhh', '##aaagggggghhhhhh', '##aaaggghhh', '##aaagghh', '##aaagongongonaarggg', '##aaammmbush', '##aaarggghh', '##aaargghhh', '##aaargghhhhhhhhhhhh', '##aaargwannawannaaaagongongonaargggaaaa', '##aaarrgghhh', '##aaarrghh', '##aaarrrgggghhhh', '##aaarrrggghhhhhhh', '##aaarrrrggggggggghhhhhh', '##aaarrrrgggggghhhhhhhhh', '##aaarrrrggggghhhhhhh', '##aaarrrrgggghhhhh', '##aaarrrrggghhhhhh', '##aaarrrrrgggghhhhhh', '##aaarrrrrrrggggggggggghhh', '##aaarrrrrrrggggggghhhhhhhh', '##aaarrrrrrrgggghhhhhhhh', '##aaauughh', '##aagggggggggggghhhhhhhhhhhh', '##aaggggggghhhhhhhhh', '##aagggggghhhhhh', '##aaggghhh', '##aagghh', '##aagghhh', '##aaghh', '##aagongongona', '##aagongongonaa', '##aagongongonaar', '##aagongongonaargg', '##aagongongonaarggg', '##aahhgghh', '##aahhghhh', '##aammmbush', '##aarggghh', '##aargghhh', '##aargghhhhhhhhhhhh', '##aarggooooooharghh', '##aarghbugg', '##aarghhhh', '##aarghnononoaarghbugg', '##aargwannawannaaaagongongonaargggaaaa', '##aarrgghh', '##aarrgghhh', '##aarrghh', '##aarrghhhooooh', '##aarrrgggghhh', '##aarrrgggghhhh', '##aarrrggghhh', '##aarrrggghhhhhhh', '##aarrrrggggggggghhhhhh', '##aarrrrgggggghhhhhhhhh', '##aarrrrggggghhhhhhh', '##aarrrrgggghhhhh', '##aarrrrggghhhhhh', '##aarrrrrgggghhhhhh', '##aarrrrrrrggggggggggghhh', '##aarrrrrrrggggggghhhhhhhh', '##aarrrrrrrgggghhhhhhhh', '##aatspoliz', '##aauugggh', '##aauugh', '##aauughh', '##abhanga', '##abiliz', '##abith', '##abithi', '##abjo', '##abjuous', '##ablishing', '##ablung', '##ablywh', '##aboliz', '##abubb', '##abyoohughh', '##abysnatching', '##achfuzzy', '##achlizards', '##achulung', '##ackjob', '##ackjord', '##acklashing', '##acklaugh', '##acklaughing', '##acqui', '##acquir', '##acquis', '##acquisi', '##acquisit', '##acquisiti', '##acquisitio', '##acquisition', '##acucumb', '##acuffs', '##acuzzi', '##adajizz', '##adawdaught', '##adbanging', '##adcrumb', '##adcrumbs', '##addaught', '##addough', '##addydaught', '##adjuri', '##adjust', '##adjusting', '##adnaught', '##adnumbjust', '##adowhung', '##adstrong', '##adstubbl', '##adybugh', '##adywhirling', '##afugg', '##agggggggggggghhhhhhhhhhhh', '##aggggggghhhhhhhhh', '##agggggghhhhhh', '##aggghhh', '##agghh', '##agghhh', '##aghh', '##aghhh', '##aghul', '##aghurry', '##aghuvir', '##agicbuzzi', '##agiliz', '##agoncouch', '##agongongona', '##agriffiths', '##ahhang', '##ahhgghh', '##ahhghhh', '##ahjong', '##ahowashington', '##ailofthought', '##ainhiphugg', '##aininjur', '##ainmatching', '##ainwashing', '##aiphong', '##aiththought', '##aithubby', '##ajang', '##ajazzl', '##ajizz', '##ajjar', '##ajji', '##ajohar', '##ajor', '##ajur', '##ajurv', '##akkkthrough', '##aknaught', '##akoczywhy', '##akthrough', '##akywhit', '##alallarumbakamandalindorburum', '##albumbcrunch', '##alfbubbl', '##alfciviliz', '##alfcough', '##alfcrashing', '##alfcrouch', '##alfcrouching', '##alfcrumbl', '##alfdistraught', '##alfdraught', '##alfdrugg', '##alfflung', '##alfhanging', '##alfjoyful', '##alflaugh', '##alflaughing', '##alfliz', '##alfmumbl', '##alfpushing', '##alfpuzzl', '##alfquizzical', '##alfrubb', '##alfshrugg', '##alfslumb', '##alfsplashing', '##alfstrangl', '##alfstumbl', '##alfsubj', '##alfthought', '##alfthoughtful', '##alftumbl', '##alfwishing', '##alhanging', '##alijongg', '##aliz', '##alkanywh', '##alkingstumblingtoward', '##alkthrough', '##alkthroughw', '##alkywhit', '##allalallarumbakamandalindorburum', '##allarumbakamandalindorburum', '##allfuzzy', '##allhanging', '##allintubb', '##alliz', '##allowdraught', '##allywh', '##allywhat', '##allywho', '##allywhy', '##almostcatatonicwithjoy', '##alogiz', '##alphjust', '##although', '##alugh', '##alumba', '##aluzzo', '##amborough', '##ambslaught', '##ambush', '##ambushing', '##amilylaughing', '##ammalugh', '##ammmbush', '##amprubbing', '##amrubb', '##anaugh', '##andcuff', '##anddaught', '##andfuzzy', '##andgrubbi', '##andlubb', '##andtumbl', '##anfrizz', '##ang', '##angbang', '##anging', '##anglungsod', '##anglyshrugg', '##angong', '##angsugg', '##anguishing', '##anjung', '##ankardclanging', '##ankmajor', '##anksrumbl', '##anlubang', '##anlumb', '##anmatching', '##annaaaagongongonaarggga', '##annaugh', '##annawannaaaagongongonaargggaaaa', '##anobotjungl', '##anquiliz', '##anquilliz', '##anquish', '##anquishing', '##anslaught', '##anssubjugat', '##antcough', '##antgowrong', '##antmajor', '##antscuffs', '##antumfuzz', '##anything', '##anythingfought', '##anythingjust', '##anythingth', '##anythingtha', '##anythingthat', '##anythingthatb', '##anythingthati', '##anywh', '##aough', '##apapaparazzi', '##apaparazzi', '##aparazzi', '##aparazzo', '##apbubbl', '##aphanging', '##aphazz', '##aphjust', '##apologiz', '##appywhich', '##apsplashing', '##apuchin', '##aqqit', '##aquishio', '##aqw', '##arabhanga', '##aralogiz', '##arazzi', '##arazzo', '##arborough', '##arbrough', '##ardclanging', '##ardfought', '##ardfoughtfor', '##ardraught', '##ardrumbursting', '##ardscruffy', '##ardstubbl', '##ardstubbly', '##ardstumbling', '##arflung', '##arfwrought', '##arggghh', '##argghhh', '##argghhhhhhhhhhhh', '##arggooooooharghh', '##arghbugg', '##arghh', '##arghhhh', '##arghnononoaarghbugg', '##arghus', '##argwannawannaaaagongongonaargggaaaa', '##aringlywhit', '##arjor', '##arjorxas', '##arkbough', '##arlclutching', '##arlywhit', '##armandfuzzy', '##armpouch', '##arong', '##arouch', '##arrang', '##arranging', '##arrggghhh', '##arrgghh', '##arrgghhh', '##arrgghhhhh', '##arrghh', '##arrghhhooooh', '##arrrgggghhh', '##arrrgggghhhh', '##arrrggghh', '##arrrggghhh', '##arrrggghhhhhhh', '##arrrrggggggggghhhhhh', '##arrrrgggggghhhhhhhhh', '##arrrrggggghhhhhhh', '##arrrrgggghhhhh', '##arrrrggghhhhhh', '##arrrrrgggghhhhhh', '##arrrrrggghhh', '##arrrrrrrggggggggggghhh', '##arrrrrrrggggggghhhhhhhh', '##arrrrrrrgggghhhhhhhh', '##arrrrrrrrrgghhhh', '##arrywizzard', '##arsthoroughly', '##artblumb', '##artycrashing', '##arumb', '##asacucumb', '##asfizzl', '##asguzzl', '##ashbang', '##ashing', '##ashingmuch', '##asobj', '##asticuffs', '##astizzi', '##atatonicwithjoy', '##atching', '##atcouldgowrong', '##atgranddaught', '##athcatching', '##athrong', '##athstruggl', '##athtouch', '##atinumblond', '##atiswrongwithm', '##atnaught', '##atonicwithjoy', '##atpong', '##atspoliz', '##atugg', '##atuggatugg', '##atuggatuggatugg', '##augh', '##aughh', '##aughhh', '##aughhhh', '##aughing', '##aught', '##aumburg', '##aumfjord', '##autifulthough', '##autyjohanna', '##auugggh', '##auuggghh', '##auugh', '##auughh', '##auuugggh', '##auuughty', '##avanaugh', '##avilydrugg', '##avishing', '##avrongo', '##awannaaaagongongonaarggga', '##awdaught', '##awpuzzl', '##awsarghh', '##awwrong', '##axilliumbut', '##axywhit', '##aydough', '##ayfought', '##ayfuzz', '##ayghost', '##ayizzy', '##aything', '##azumba', '##azywhat', '##azz', '##azzz', '##b', '##bablywh', '##bang', '##bangbang', '##banging', '##baugh', '##bb', '##bbing', '##bciviliz', '##bcrushing', '##bhang', '##bhanga', '##bhanging', '##biliz', '##bith', '##bj', '##bjo', '##bjor', '##bjorn', '##bju', '##bjuo', '##bjuou', '##bjuous', '##bjus', '##bjust', '##bjw', '##blishing', '##blizz', '##blizza', '##blizzar', '##blizzard', '##blubb', '##blumb', '##blung', '##blushing', '##blywh', '##boliz', '##borough', '##bothlaughingh', '##botjungl', '##bouch', '##bough', '##boughs', '##bought', '##boybugg', '##braught', '##brough', '##brought', '##broughtu', '##broughtup', '##brushing', '##bsubb', '##bubb', '##bubbl', '##buch', '##buff', '##bugg', '##bugging', '##buggl', '##bugh', '##bumb', '##bumbc', '##bumbl', '##buzz', '##buzzbuzz', '##buzzi', '##buzzin', '##buzzing', '##byoohughh', '##bysnatching', '##c', '##callywhat', '##callywhy', '##carborough', '##catatonicwithjoy', '##catching', '##caught', '##cbuzz', '##cbuzzi', '##cbuzzk', '##ccomplishing', '##ccouch', '##ccough', '##ccumb', '##cdraught', '##cguffy', '##ch', '##chang', '##changing', '##chaumburg', '##chboughs', '##chcoughing', '##chcuff', '##chfuzzy', '##chgrubby', '##chhang', '##chhugging', '##ching', '##chliz', '##chliza', '##chlizar', '##chlizard', '##chlizards', '##chlubb', '##chnologywhil', '##chompingscratching', '##chsmashing', '##chthumb', '##chubby', '##chugchugging', '##chugging', '##chulung', '##cificallywhat', '##civiliz', '##cizzy', '##ck', '##ckapologiz', '##ckatnaught', '##ckborough', '##ckfuzz', '##ckhang', '##ckhanga', '##ckhangar', '##ckjob', '##ckjor', '##ckjord', '##cklashing', '##cklaugh', '##cklaughing', '##cklugg', '##cklung', '##ckobj', '##ckpouch', '##cksmashing', '##cktumbl', '##ckwatching', '##clanging', '##clangsugg', '##claugh', '##cliffhang', '##cloudrumbl', '##clough', '##clubb', '##clubby', '##clung', '##clutching', '##cnaught', '##cnugg', '##complishing', '##conjur', '##conjuri', '##conjurin', '##conjuring', '##couch', '##cough', '##coughc', '##coughing', '##coughs', '##coughsh', '##coughsho', '##coughshoo', '##coughshoot', '##coughshooti', '##coughshootin', '##couldgowrong', '##cqui', '##crashing', '##cratching', '##crazywhat', '##crdfngh', '##crouch', '##crouching', '##crubb', '##crubby', '##cruffy', '##crumb', '##crumbl', '##crumbs', '##crushing', '##ctrocuffs', '##cubb', '##cucumb', '##cuff', '##cuffs', '##cugg', '##cuitacquisition', '##cumb', '##cumbl', '##cuzz', '##cuzzi', '##cwithjoy', '##cything', '##czywh', '##czywhy', '##d', '##daghh', '##dahowashington', '##dajizz', '##danythingthat', '##daught', '##dawdaught', '##dbanging', '##dclanging', '##dconjur', '##dcrumb', '##dcrumbs', '##dcuff', '##dcuffy', '##ddaught', '##ddishthought', '##ddough', '##ddydaught', '##dfinallywh', '##dfngh', '##dfought', '##dfoughtf', '##dfoughtfo', '##dfoughtfor', '##dfuzz', '##dfuzzy', '##dgoallfuzzy', '##dgowrong', '##dgrubb', '##dgrubbi', '##dgrubbs', '##dgrumbl', '##dgushing', '##dhumbling', '##diminishing', '##dingthqw', '##diough', '##disfjordu', '##dishclubb', '##dishthought', '##dispatching', '##distraught', '##diumblond', '##diumblood', '##diumbloodt', '##diumbloodth', '##diumbu', '##diumbui', '##diumbuil', '##diumbuild', '##diumbut', '##dizzl', '##djoong', '##djur', '##djuri', '##djus', '##djust', '##dlubb', '##dnaught', '##dnumbing', '##dnumbjust', '##doanythingthati', '##doliz', '##donmcqui', '##donnaugh', '##dontwanging', '##dough', '##dowhung', '##dowrong', '##dowrongwrong', '##dplunging', '##dpuffy', '##draught', '##draughts', '##drikalbumbcrunch', '##drizzl', '##drugg', '##drumbl', '##drumbu', '##drumbur', '##drumburs', '##drumburst', '##drumbursting', '##dscruffy', '##dsnatching', '##dsshrugg', '##dstrong', '##dstruggl', '##dstubbl', '##dstubbly', '##dstumbl', '##dstumbling', '##dthqw', '##dtumbl', '##dubb', '##dugg', '##dulrazzaq', '##dumbly', '##dumbu', '##dybugh', '##dydaught', '##dyhugging', '##dysnatching', '##dyswung', '##dywhi', '##dywhir', '##dywhirl', '##dywhirling', '##dzzzzzt', '##dzzzzzti', '##dzzzzztit', '##e', '##f', '##fanging', '##fblubb', '##fbubbl', '##fciviliz', '##fcough', '##fcrashing', '##fcrouch', '##fcrouching', '##fcrumbl', '##fdistraught', '##fdraught', '##fdrugg', '##ff', '##ffff', '##fffff', '##ffffff', '##fffffff', '##ffffffff', '##ffffffffff', '##ffffffffffffffff', '##fffffffj', '##ffincouch', '##fflung', '##fflushing', '##fgh', '##fghh', '##fhanging', '##ficallywhat', '##finallywh', '##finishing', '##finjur', '##finjury', '##fizz', '##fizzl', '##fjor', '##fjord', '##fjordu', '##fjoyf', '##fjoyfu', '##fjoyful', '##flashing', '##flaugh', '##flaughing', '##flaught', '##fliz', '##fluffy', '##flung', '##flushing', '##fmumbl', '##fngh', '##fough', '##fought', '##fpubb', '##fpublishing', '##fpushing', '##fpuzzl', '##fquizz', '##fraught', '##frazz', '##frazzl', '##frizz', '##frizzing', '##frubb', '##fshrugg', '##fshuffling', '##fslumb', '##fsplashing', '##fstrang', '##fstrangl', '##fstumbl', '##fsubj', '##ftaught', '##ftfluffy', '##fthought', '##ftumbl', '##fugg', '##fullylaugh', '##fullywh', '##fulthough', '##fumbl', '##fuzz', '##fuzzing', '##fuzzy', '##fwishing', '##fwrought', '##fyoutouchh', '##g', '##gainhiphugg', '##gbang', '##gbj', '##gbugging', '##gcaught', '##gchugchugging', '##gchugging', '##gg', '##gggggggggggghhhhhhhhhhhh', '##gggggggggggghhhhhhhhhhhhhh', '##gggggggggggh', '##ggggggggggghh', '##ggggggggggghhh', '##gggggggggghhhhhhhhhhhh', '##gggggggggghhhhhhhhhhhhhh', '##gggggggggh', '##ggggggggghh', '##ggggggggghhh', '##ggggggggghhhh', '##ggggggggghhhhh', '##ggggggggghhhhhh', '##gggggggghhhhhhhhhhhh', '##gggggggghhhhhhhhhhhhhh', '##gggggggh', '##ggggggghh', '##ggggggghhh', '##ggggggghhhh', '##ggggggghhhhh', '##ggggggghhhhhh', '##ggggggghhhhhhh', '##ggggggghhhhhhhh', '##ggggggghhhhhhhhh', '##gggggghh', '##gggggghhhh', '##gggggghhhhh', '##gggggghhhhhh', '##gggggghhhhhhhhh', '##gggggghhhhhhhhhhhh', '##gggggghhhhhhhhhhhhhh', '##gggggghhl', '##gggggghhll', '##gggggghhlll', '##gggggghhllll', '##gggggghhllllh', '##gggggghhllllhh', '##gggggh', '##ggggghh', '##ggggghhh', '##ggggghhhh', '##ggggghhhhh', '##ggggghhhhhh', '##ggggghhhhhhh', '##ggggghhhhhhhh', '##ggggghhhhhhhhh', '##gggghh', '##gggghhh', '##gggghhhh', '##gggghhhhh', '##gggghhhhhh', '##gggghhhhhhhh', '##gggghhhhhhhhh', '##gggghhhhhhhhhhhh', '##gggghhhhhhhhhhhhhh', '##gggh', '##ggghh', '##ggghhh', '##ggghhhh', '##ggghhhhh', '##gghghg', '##gghh', '##gghhh', '##gghhhh', '##gghhhhh', '##gghhhhhh', '##gghhhhhhhh', '##gghhhhhhhhh', '##gghhhhhhhhhhhh', '##gghhhhhhhhhhhhhh', '##gghhw', '##gging', '##ggooooooharghh', '##ggrubb', '##gh', '##ghandtumbl', '##ghang', '##ghbugg', '##ghbuzzing', '##ghfgh', '##ghgh', '##ghghg', '##ghh', '##ghhh', '##ghhhh', '##ghhhhh', '##ghhhhhh', '##ghhhhhhh', '##ghhhhhhhh', '##ghhhhhhhhh', '##ghhhhhhhhhh', '##ghhhhhhhhhhh', '##ghhhhhhhhhhhh', '##ghhhhhhhhhhhhh', '##ghhhhhhhhhhhhhh', '##ghnononoaarghbugg', '##ghtclubb', '##ghtpizz', '##ghu', '##ghul', '##ghum', '##ghung', '##ghur', '##ghurr', '##ghurry', '##ghus', '##ghuv', '##ghuvi', '##ghuvir', '##gicallywhy', '##gicbuzzi', '##giliz', '##giz', '##gizz', '##gizza', '##gizzar', '##gizzard', '##gizzardg', '##gizzardgu', '##gizzardgul', '##gizzardgulp', '##gjob', '##gmuzz', '##gmuzzl', '##goallfuzzy', '##goingoutclubbi', '##goncouch', '##gongong', '##gongongo', '##gongongon', '##gongongona', '##gorongo', '##goutclubb', '##goutclubbi', '##gowrong', '##granddaught', '##graphjust', '##griffith', '##griffiths', '##grizzl', '##grizzly', '##grouch', '##grubb', '##grubby', '##gruggl', '##grumbl', '##grumbli', '##gsawpuzzl', '##gslaught', '##gslumb', '##gsmashing', '##gsmuggl', '##gsmuggling', '##gstumbl', '##gstumbli', '##gstumblin', '##gstumbling', '##gstumblingt', '##gstumblingtow', '##gstumblingtowa', '##gstumblingtowar', '##gstumblingtoward', '##gswizzl', '##gthqw', '##guffy', '##guninjur', '##gushing', '##guzz', '##guzzl', '##guzzli', '##guzzlin', '##guzzling', '##gwannawannaaaagongongonaargggaaaa', '##gynaught', '##gynaughts', '##gywhi', '##gywhil', '##h', '##haghh', '##handtumbl', '##hang', '##hangbhang', '##hangh', '##hanging', '##harghh', '##hashing', '##haugh', '##haumburg', '##hboughs', '##hbugg', '##hclubb', '##hcoughing', '##hdubb', '##hfuzzy', '##hgghh', '##hghhh', '##hgrubby', '##hhang', '##hhbugg', '##hhgghh', '##hhghhh', '##hhouaough', '##hhrrggghh', '##high', '##hinganythingfought', '##hingfought', '##hiphugg', '##hirttugging', '##hishizzl', '##hizz', '##hizzl', '##hjong', '##hjusthigh', '##hlubb', '##hluggi', '##hlyscrubb', '##hngh', '##hngho', '##hnghos', '##hocktumbl', '##hoirboybugg', '##hongq', '##hopbought', '##horough', '##horoughl', '##horoughly', '##hostlywhit', '##hotguninjur', '##houaough', '##hough', '##how', '##howashing', '##howashingt', '##howashingto', '##howashington', '##howstrang', '##howthrough', '##howwrong', '##hpuch', '##hpzzzzzzzzzz', '##hqw', '##hrough', '##hrrggghh', '##hrubb', '##hrubby', '##hrugg', '##hrugging', '##hscrubb', '##hslaught', '##hstruggl', '##htclubb', '##hthumb', '##hthumbs', '##htpizz', '##hubb', '##hubby', '##hubj', '##hugg', '##hugging', '##hugh', '##hughh', '##humb', '##humbl', '##humbling', '##humbu', '##hung', '##huuugh', '##huzz', '##i', '##ibcrushing', '##ibith', '##ibiths', '##ibjo', '##ibubbl', '##icallywhat', '##icallywhy', '##icbuzzi', '##iccough', '##iciviliz', '##ickatnaught', '##icklugg', '##ickluggi', '##ickluggin', '##icrouch', '##icuffs', '##icwithjoy', '##idcuffy', '##iddishthought', '##idgrubbs', '##idiumbut', '##idowrong', '##idstruggl', '##idstumbl', '##iff', '##iffhang', '##iffhanging', '##iffith', '##ificallywhat', '##ifrizz', '##iftfluffy', '##ifulthough', '##ifyoutouchh', '##igbang', '##igggghhh', '##igh', '##ighang', '##ighb', '##ighbo', '##ighbor', '##ighborh', '##ighborho', '##ighborhoo', '##ighborhood', '##ighboring', '##ighbors', '##ighbou', '##ighbour', '##ighbourh', '##ighbourho', '##ighbourhoo', '##ighbourhood', '##ighbouring', '##ighbours', '##ighbuzzing', '##ighing', '##ight', '##ightclubb', '##ightcough', '##ightjust', '##ightjustb', '##ightjustp', '##ightlywh', '##ightlywhy', '##ightpizz', '##igjob', '##igsawpuzzl', '##igslaught', '##iigggghhh', '##iiigggghhh', '##iiiigggghhh', '##iiiiigggghhh', '##iiiiiigggghhh', '##ijang', '##ijja', '##ijongg', '##ijung', '##ikalbumbcrunch', '##ikjor', '##ildsnatching', '##iliz', '##iljuju', '##iljus', '##ilkywhit', '##illanythingthatb', '##illaquishio', '##illbjorn', '##illcrouching', '##illhanging', '##illiumbut', '##illiz', '##illjoy', '##illoughby', '##illowboughs', '##illowjungl', '##illsizzling', '##illsluggish', '##illstruggling', '##illybumbl', '##illywhat', '##ilofthought', '##ilosqwis', '##ilosqwism', '##ilwhackjob', '##ilydrugg', '##ilylaughing', '##ilywhit', '##imapologiz', '##imbrough', '##imbulung', '##imflashing', '##imhanging', '##iminishing', '##imstumbling', '##inallywh', '##incouch', '##indgoallfuzzy', '##indhumbling', '##indnumbing', '##indrikalbumbcrunch', '##ing', '##inganythingfought', '##inganywh', '##ingbugg', '##ingchompingscratching', '##ingdraught', '##ingfought', '##inglywhit', '##ingoutclubbi', '##ingpong', '##ingpongb', '##ingscratching', '##ingslaught', '##ingstumblingtoward', '##ingsubj', '##ingsugg', '##ingthqw', '##ingugh', '##inguishing', '##inhiphugg', '##inillaquishio', '##ininjur', '##inishing', '##injur', '##injuring', '##inkinghangov', '##inkplung', '##inkthrough', '##inkywhit', '##inmatching', '##innbjorn', '##innyflashing', '##innylaugh', '##inquish', '##inquishing', '##intopingpongb', '##intubb', '##inturong', '##inumblond', '##inwashing', '##inylaugh', '##inywhydid', '##iough', '##iouspuzzl', '##iphong', '##iphugg', '##iphugging', '##iplashing', '##ippfizz', '##ippydizzl', '##ippythings', '##ipsybugg', '##iqh', '##iquijor', '##iquish', '##iradjuri', '##irboybugg', '##irchboughs', '##iriumbutor', '##irjurg', '##irlalmostcatatonicwithjoy', '##irlclutching', '##irouch', '##irttugging', '##irtyaughtsix', '##iscuitacquisition', '##isfjordu', '##ish', '##ishclubb', '##ishing', '##ishizzl', '##ishmong', '##ishsplashing', '##ishthought', '##ishwashing', '##isonwishing', '##ispatching', '##issizz', '##issrissizz', '##istacuffs', '##isticuffs', '##istinguishing', '##istraught', '##istsmashing', '##istthumb', '##istyjungl', '##iswrongwithm', '##itacquisition', '##itchlizard', '##itfrazzl', '##ith', '##ithjoy', '##ithstrang', '##iththought', '##iththumbs', '##ithubby', '##itzhugh', '##iumblond', '##iumblood', '##iumbu', '##iumbut', '##iumbuto', '##iumbutor', '##iviliz', '##iz', '##izazz', '##izbang', '##izz', '##izzb', '##izzi', '##izzk', '##izzl', '##izzy', '##izzz', '##izzzz', '##izzzzzy', '##j', '##jacklaugh', '##jang', '##jangl', '##jazz', '##jazzl', '##jizz', '##jj', '##jja', '##jjar', '##jji', '##jju', '##jo', '##job', '##joh', '##joha', '##johar', '##johf', '##john', '##johnghos', '##jong', '##jongg', '##joong', '##jor', '##jorx', '##joy', '##joyf', '##joyfu', '##joyful', '##joying', '##ju', '##juju', '##jumb', '##jumbl', '##jumbo', '##jung', '##jungl', '##jur', '##juri', '##jurin', '##jurv', '##jury', '##jus', '##jush', '##just', '##justhigh', '##justhow', '##juv', '##k', '##kalbumbcrunch', '##kanywh', '##kardclanging', '##kazz', '##kbough', '##kchang', '##kdaught', '##kfizzl', '##khough', '##killanythingthatb', '##king', '##kinghang', '##kinghango', '##kinghangov', '##kingstumblingtoward', '##kinnyflashing', '##kjang', '##kjangl', '##kjor', '##kkkthrough', '##kkthrough', '##kmajor', '##knaught', '##knowjusthowyouf', '##koczywhy', '##kplung', '##krong', '##krough', '##ksrumbl', '##kthrough', '##kthroughw', '##kugg', '##kuldugg', '##kulldugg', '##kuzz', '##kydaught', '##kygh', '##kyghu', '##kywhit', '##l', '##laghhh', '##laghurry', '##lakywhit', '##lalallarumbakamandalindorburum', '##lallalallarumbakamandalindorburum', '##lallarumbakamandalindorburum', '##lalmostcatatonicwithjoy', '##landlubb', '##langbang', '##langing', '##langsugg', '##lanksrumbl', '##lanythingthatb', '##lapsplashing', '##laquishio', '##laringlywhit', '##larumb', '##lasacucumb', '##lashbang', '##lashing', '##lasticuffs', '##latching', '##latinumblond', '##laugh', '##laughing', '##laughingh', '##laught', '##lawsarghh', '##laydough', '##layfought', '##laything', '##lbanging', '##lbjorn', '##lbroughtup', '##lbumbc', '##lbumbcr', '##lbumbcru', '##lbumbcrun', '##lbumbcrunc', '##lbumbcrunch', '##lclutching', '##lcrouching', '##ldanythingthat', '##ldgowrong', '##ldiough', '##ldsnatching', '##ldugg', '##lfblubb', '##lfbubbl', '##lfciviliz', '##lfcough', '##lfcrashing', '##lfcrouch', '##lfcrouching', '##lfcrumbl', '##lfdistraught', '##lfdraught', '##lfdrugg', '##lfflung', '##lfflushing', '##lfhanging', '##lfinjury', '##lfjord', '##lfjoyful', '##lflaugh', '##lflaughing', '##lfliz', '##lfmumbl', '##lfpubb', '##lfpubbo', '##lfpubboo', '##lfpubbook', '##lfpubbookc', '##lfpubbookco', '##lfpubbookcov', '##lfpublishing', '##lfpushing', '##lfpuzzl', '##lfquizz', '##lfquizzi', '##lfquizzic', '##lfquizzica', '##lfquizzical', '##lfrubb', '##lfshrugg', '##lfshuffling', '##lfslumb', '##lfsplashing', '##lfstrangl', '##lfstumbl', '##lfsubj', '##lfsubju', '##lfsubjug', '##lfsubjuga', '##lfsubjugat', '##lfsubjugati', '##lfsubjugatio', '##lfsubjugation', '##lftaught', '##lfthought', '##lfthoughtf', '##lfthoughtfu', '##lfthoughtful', '##lftumbl', '##lfuzzy', '##lfwishing', '##lfwrought', '##lhanging', '##lidstumbl', '##liffhang', '##liffhanging', '##lightjust', '##lightlywhy', '##lijongg', '##lindrikalbumbcrunch', '##linganywh', '##lingbugg', '##lingugh', '##linquish', '##linquishing', '##lintubb', '##liquish', '##lishing', '##lishsplashing', '##liumbut', '##liz', '##lizz', '##lizzy', '##ljoy', '##ljuju', '##ljus', '##lkanywh', '##lkingstumblingtoward', '##lkthrough', '##lkthroughw', '##lkywhit', '##llaghhh', '##llalallarumbakamandalindorburum', '##llanythingthatb', '##llaquishio', '##llarumb', '##llarumba', '##llarumbak', '##llarumbaka', '##llarumbakam', '##llarumbakama', '##llarumbakaman', '##llarumbakamand', '##llarumbakamanda', '##llarumbakamandal', '##llarumbakamandali', '##llarumbakamandalin', '##llarumbakamandalind', '##llarumbakamandalindo', '##llarumbakamandalindor', '##llarumbakamandalindorb', '##llarumbakamandalindorbu', '##llarumbakamandalindorbur', '##llarumbakamandalindorburu', '##llarumbakamandalindorburum', '##llbjorn', '##llbroughtup', '##llcrouching', '##lldugg', '##llfuzzy', '##llhanging', '##llingbugg', '##llingugh', '##llintubb', '##lliumbut', '##lliz', '##lljoy', '##lloughby', '##llowbough', '##llowboughs', '##llowdraught', '##llowjung', '##llowjungl', '##llowthrough', '##llplugg', '##llscrubb', '##llsizzling', '##llsluggish', '##llstruggling', '##llswung', '##llthough', '##llthought', '##llthoughto', '##llthoughtof', '##llthoughtou', '##llthoughtout', '##llthumb', '##llwishing', '##llybumbl', '##llydough', '##llydoughn', '##llydoughnu', '##llydoughnut', '##llylaugh', '##llywh', '##llywha', '##llywhat', '##llywho', '##llywhom', '##llywhy', '##lmostcatatonicwithjoy', '##lmuwaqqit', '##loaaaaaaaauughh', '##lockwatching', '##lofthought', '##logicallywhy', '##logiz', '##logywhil', '##long', '##longing', '##longings', '##loodgushing', '##loogynaughts', '##loorscrubbing', '##losqw', '##losqwi', '##losqwis', '##losqwism', '##lothinglashing', '##louch', '##louching', '##loudrumbl', '##lough', '##loughb', '##loughby', '##lowbough', '##lowdraught', '##lowjob', '##lowjung', '##lowthrough', '##lpaarghnononoaarghbugg', '##lphjust', '##lpingpong', '##lpingpongs', '##lpingpongsc', '##lpingpongsca', '##lpingpongscam', '##lpingpongscams', '##lplugg', '##lpushing', '##lrazzaq', '##lrightcough', '##lrylaughing', '##lscrubb', '##lsizzling', '##lsluggish', '##lstruggling', '##lswung', '##lthough', '##lthumb', '##ltsstruggl', '##lubang', '##lubb', '##lubby', '##luffy', '##luffywh', '##lugg', '##luggi', '##lugging', '##lugh', '##lumb', '##lumba', '##lumbl', '##lumpjang', '##lung', '##lunging', '##lungingung', '##lunkjangl', '##lushing', '##lutching', '##luugh', '##luzz', '##luzzo', '##lwhackjob', '##lwishing', '##lyacquir', '##lybumbl', '##lydaught', '##lydough', '##lydrugg', '##lydumbly', '##lydumblys', '##lydumblyst', '##lydumblystr', '##lydumblystru', '##lydumblystruck', '##lylaugh', '##lylaughing', '##lyobj', '##lyscrubb', '##lyshrugg', '##lystyliz', '##lywh', '##lywhisk', '##lywhit', '##lywhy', '##m', '##machlizards', '##major', '##majorc', '##majoring', '##mallywhat', '##malugh', '##mandfuzzy', '##manslaught', '##manssubjugat', '##mapologiz', '##mashing', '##matching', '##mathrong', '##maugh', '##mb', '##mbaugh', '##mbju', '##mbliz', '##mboliz', '##mborough', '##mbrough', '##mbslaught', '##mbulung', '##mbush', '##mbushing', '##mcqui', '##mfjor', '##mflashing', '##mfuzz', '##mhanging', '##miciviliz', '##microuch', '##milylaughing', '##mindgoallfuzzy', '##minishing', '##mizzy', '##mmalugh', '##mmbush', '##mmmbush', '##mmmnngh', '##mmnngh', '##mmobiliz', '##mmydaught', '##mnngh', '##mobiliz', '##molishing', '##mondispatching', '##mong', '##monywh', '##monywha', '##monywhat', '##mostcatatonicwithjoy', '##mpanywh', '##mpanywhi', '##mpanywhich', '##mphith', '##mpingscratching', '##mpjang', '##mplishing', '##mpouch', '##mprubbing', '##mpublishing', '##mrubb', '##mstrong', '##mstumbl', '##mstumbli', '##mstumblin', '##mstumbling', '##mthumb', '##much', '##mugg', '##muggl', '##muggling', '##mugh', '##mugho', '##mughol', '##mughold', '##mugholding', '##mumbl', '##mumbling', '##mushing', '##muwaqqit', '##muzz', '##mydaught', '##myonlydaught', '##n', '##naaaagongongonaarggg', '##naahhghhh', '##nallywh', '##natching', '##naugh', '##naught', '##naughty', '##naughtys', '##nawannaaaagongongonaarggga', '##nbangbang', '##nbjorn', '##nchcuff', '##nchubby', '##ncouch', '##ncrouching', '##ncumb', '##ndaghh', '##ndcuff', '##nddaught', '##ndfuzzy', '##ndgoallfuzzy', '##ndgrubbi', '##ndhumbling', '##ndingthqw', '##ndishclubb', '##ndispatching', '##ndjoong', '##ndlubb', '##ndnumbing', '##ndontwanging', '##ndrikalbumbcrunch', '##ndsshrugg', '##ndtumbl', '##ndumbu', '##ndumbut', '##ndzzzzztit', '##nfluffy', '##nflushing', '##nfrizz', '##nfuzz', '##ng', '##ngghh', '##ngghhh', '##ngh', '##nghi', '##nghis', '##nghiz', '##nghu', '##nghuang', '##nglung', '##nglungs', '##nglungso', '##nglungsod', '##nglyshrugg', '##ngmuzzl', '##ngoutclubbi', '##ngrizzly', '##ngrumbli', '##ngslumb', '##ngsought', '##ngstumblingtoward', '##ngswizzl', '##ngth', '##ngthqw', '##ngththough', '##ngththought', '##nguishing', '##nhiphugg', '##nicwithjoy', '##nillaquishio', '##ninjur', '##nishing', '##njong', '##njoy', '##njoying', '##njoyth', '##njung', '##njunga', '##njungah', '##njungaht', '##njungahtm', '##njungahtml', '##njur', '##nkardclanging', '##nkinghangov', '##nkjangl', '##nkmajor', '##nkplung', '##nksrumbl', '##nkthrough', '##nkywhit', '##nlandlubb', '##nlightjust', '##nljoy', '##nlubang', '##nlumb', '##nlydaught', '##nlydumblystruck', '##nmatching', '##nmcqui', '##nnaaaagongongonaarggg', '##nnaaaagongongonaarggga', '##nnaugh', '##nnawannaaaagongongonaarggga', '##nnawannaaaagongongonaargggaa', '##nnawannaaaagongongonaargggaaa', '##nnawannaaaagongongonaargggaaaa', '##nnbjorn', '##nngghhh', '##nngh', '##nnngh', '##nnyflashing', '##nnylaugh', '##nnywh', '##nnywhistl', '##noaarghbugg', '##nobotjungl', '##nologywhil', '##nonoaarghbugg', '##nononoaarghbugg', '##nopoliz', '##notgoingoutclubbingwithsimo', '##notgoingoutclubbingwithsimon', '##notgoingoutclubbingwithsimona', '##notgoingoutclubbingwithsimonaf', '##notgoingoutclubbingwithsimonaft', '##nough', '##nowanywh', '##nowfought', '##nowhang', '##nowjob', '##nowjusthowyouf', '##nowplough', '##nowywhit', '##nozzcumb', '##nplumb', '##nplung', '##npuch', '##nquiliz', '##nquilliz', '##nquish', '##nquishing', '##nschlubb', '##nshrugging', '##nsintopingpongb', '##nsizzl', '##nslaught', '##nssubjug', '##nssubjuga', '##nssubjugat', '##ntasobj', '##ntcough', '##ntdoanythingthatinvolv', '##ntdraughts', '##ntgowrong', '##ntifrizz', '##ntlyacquir', '##ntmajor', '##ntopingpongb', '##ntothqw', '##ntrillywhat', '##ntrillywhats', '##ntrillywhatsi', '##ntrillywhatsit', '##ntrilosqwism', '##ntrilosqwist', '##ntscuffs', '##nttumbling', '##ntubb', '##ntumfuzz', '##nturong', '##ntvanquishing', '##ntwanging', '##nubb', '##nuffy', '##nugg', '##nugging', '##nuggl', '##numb', '##numbing', '##numbjust', '##numblond', '##nuzz', '##nwashing', '##nwishing', '##nyflashing', '##nylaugh', '##nything', '##nythingfought', '##nythingjust', '##nywh', '##nywhi', '##nywhis', '##nywhist', '##nywhistl', '##nywhit', '##nywhy', '##nywhyd', '##nywhydi', '##nywhydid', '##o', '##oaaaaaaaauughh', '##oaarghbugg', '##oallfuzzy', '##oamrubb', '##oanythingthati', '##oapbubbl', '##obablywh', '##obhanging', '##obiliz', '##obj', '##objust', '##obotjungl', '##ocizzy', '##ockapologiz', '##ocksmashing', '##ocktumbl', '##ockwatching', '##ocuffs', '##oczywhy', '##odconjur', '##oddaught', '##odfuzz', '##odgushing', '##odyhugging', '##odysnatching', '##odyswung', '##offfff', '##offincouch', '##ofthought', '##ogbugging', '##ogcaught', '##oghum', '##oghung', '##ogicallywhy', '##ogiz', '##ographjust', '##ogswizzl', '##ogynaughts', '##ogywhil', '##oharghh', '##ohhbugg', '##ohnghos', '##ohughh', '##ohumbl', '##oingoutclubbi', '##oirboybugg', '##oisonwishing', '##ojoh', '##ojoyful', '##ojumbo', '##ojush', '##okchang', '##olasacucumb', '##olindrikalbumbcrunch', '##olishing', '##oliz', '##ollowthrough', '##ollywhat', '##ollywhom', '##ologiz', '##ologywhil', '##oltsstruggl', '##olumb', '##omachlizards', '##omanslaught', '##omborough', '##omizzy', '##ompanywhich', '##ompingscratching', '##omplishing', '##oncouch', '##ondispatching', '##ong', '##ongbanging', '##onghigh', '##ongmuzzl', '##ongong', '##ongq', '##ongslumb', '##ongsought', '##onicwithjoy', '##oninjur', '##onjur', '##onlydaught', '##onmcqui', '##onnaugh', '##onoaarghbugg', '##ononoaarghbugg', '##onopoliz', '##onsintopingpongb', '##onsintopingpongba', '##onsintopingpongbal', '##onsintopingpongball', '##onsintopingpongballs', '##ontdoanythingthatinvolv', '##ontwanging', '##onwishing', '##onywh', '##oodconjur', '##oodfuzz', '##oodgushing', '##oofffff', '##oogynaughts', '##ooharghh', '##oohughh', '##ookchang', '##oolasacucumb', '##ooofffff', '##oooharghh', '##oooofffff', '##ooooharghh', '##ooooofffff', '##oooooharghh', '##oooooofffff', '##ooooooharghh', '##ooooooooopppppppppppppppzzzzzzzzzzzzz', '##oooooooopppppppppppppppzzzzzzzzzzzzz', '##ooooooopppppppppppppppzzzzzzzzzzzzz', '##oooooopppppppppppppppzzzzzzzzzzzzz', '##ooooopppppppppppppppzzzzzzzzzzzzz', '##oooopppppppppppppppzzzzzzzzzzzzz', '##ooopppppppppppppppzzzzzzzzzzzzz', '##oopppppppppppppppzzzzzzzzzzzzz', '##oorbanging', '##oorscrubbing', '##oorwaythingy', '##opbought', '##ophugging', '##opingpongb', '##opmugg', '##opoliz', '##opppppppppppppppzzzzzzzzzzzzz', '##oppsywhiffling', '##oqq', '##oqw', '##oradawdaught', '##orbanging', '##orghum', '##orizzz', '##orkdaught', '##orkrough', '##orldanythingthat', '##ormathrong', '##orongo', '##orough', '##oroughlyobj', '##orscrubbing', '##ortrang', '##orwaythingy', '##osoliz', '##osqw', '##ossdraught', '##osshatching', '##ossiliz', '##ostcatatonicwithjoy', '##ostlywhit', '##ostpizza', '##osugg', '##otchhang', '##otchhugging', '##otfjord', '##otgoingoutclubbi', '##otgoingoutclubbin', '##otgoingoutclubbing', '##otgoingoutclubbingw', '##otgoingoutclubbingwi', '##otgoingoutclubbingwit', '##otgoingoutclubbingwith', '##otgoingoutclubbingwiths', '##otgoingoutclubbingwithsi', '##otgoingoutclubbingwithsim', '##otgoingoutclubbingwithsimo', '##otguninjur', '##othbrushing', '##othinglashing', '##othlaugh', '##othlaughingh', '##othqw', '##otjungl', '##otmumbling', '##otrang', '##ouaough', '##ouch', '##ouching', '##ouchong', '##oudrumbl', '##ouggi', '##ough', '##oughandtumbl', '##oughb', '##oughby', '##oughlyobj', '##ought', '##ouldgowrong', '##ounttumbling', '##ouphugging', '##ourdough', '##ourmindgoallfuzzy', '##ouspuzzl', '##outclubb', '##outhbrushing', '##outhwashingmo', '##outouchh', '##ovingchompingscratching', '##ow', '##owanywh', '##owbough', '##owdraught', '##owfought', '##owhang', '##owhanging', '##owhung', '##owjob', '##owjung', '##owjusthow', '##owjusthowy', '##owjusthowyo', '##owjusthowyou', '##owjusthowyouf', '##owngrizzly', '##owplough', '##owrong', '##owrongwrong', '##owslung', '##owthrough', '##owywhit', '##oybugg', '##oybuzz', '##oyjohnghos', '##oysclubby', '##ozozzzzztapp', '##ozzcumb', '##ozzy', '##ozzzzztapp', '##p', '##paarghnononoaarghbugg', '##panywh', '##papaparazzi', '##paparazzi', '##parazzi', '##parazzo', '##patching', '##pazz', '##pbought', '##pbubbl', '##pdaught', '##pfuzz', '##pgranddaught', '##ph', '##phanging', '##phazz', '##phith', '##phjust', '##phong', '##phugg', '##phugging', '##phywh', '##pidgrubbs', '##pingdraught', '##pingpong', '##pingpongb', '##pingscratching', '##pizz', '##pjang', '##plashing', '##plishing', '##plishsplashing', '##plough', '##plugg', '##plugging', '##plumb', '##plung', '##plunging', '##pmugg', '##polishing', '##poliz', '##pologiz', '##pong', '##pouch', '##pp', '##ppfizz', '##pping', '##ppologiz', '##pppologiz', '##pppppppppppppppzzzzzzzzzzzzz', '##ppppppppppppppzzzzzzzzzzzzz', '##pppppppppppppzzzzzzzzzzzzz', '##ppppppppppppzzzzzzzzzzzzz', '##pppppppppppzzzzzzzzzzzzz', '##ppppppppppzzzzzzzzzzzzz', '##pppppppppzzzzzzzzzzzzz', '##ppppppppzzzzzzzzzzzzz', '##pppppppzzzzzzzzzzzzz', '##ppppppzzzzzzzzzzzzz', '##pppppzzzzzzzzzzzzz', '##ppppzzzzzzzzzzzzz', '##pppzzzzzzzzzzzzz', '##ppsywhiffling', '##ppydizzl', '##ppything', '##ppythings', '##ppywhich', '##ppzzzzzzzzzzzzz', '##prang', '##prong', '##prubbing', '##psplashing', '##psugg', '##psybugg', '##ptpublishingcom', '##pubb', '##publishing', '##publishingc', '##publishingco', '##publishingcom', '##puch', '##puchi', '##puchin', '##puffy', '##pushing', '##puzz', '##puzzl', '##pzzz', '##pzzzzzzzzzz', '##pzzzzzzzzzzzzz', '##q', '##qh', '##qq', '##qqi', '##qqit', '##qu', '##qui', '##quijor', '##quiliz', '##quilliz', '##quish', '##quishi', '##quishing', '##quishio', '##quizz', '##qw', '##qx', '##r', '##rabhanga', '##rabithi', '##rabithia', '##rabjo', '##rabjuous', '##radawdaught', '##radjuri', '##ragiliz', '##ragoncouch', '##raininjur', '##rainmatching', '##rainwashing', '##ralogiz', '##rambushing', '##randdaught', '##rang', '##ranging', '##rannaugh', '##ranquiliz', '##ranquilliz', '##raphanging', '##raphjust', '##rashing', '##ratching', '##raught', '##raumfjord', '##rayfuzz', '##razywhat', '##razz', '##razza', '##razzaq', '##razzi', '##razzo', '##rbanging', '##rbjor', '##rbju', '##rbjui', '##rbjuic', '##rborough', '##rboybugg', '##rbrough', '##rbugging', '##rchang', '##rchboughs', '##rchugging', '##rcliffhang', '##rcloudrumbl', '##rconjuring', '##rcoughing', '##rcrumbl', '##rcrumbli', '##rcrumblin', '##rcrumbling', '##rcrumbs', '##rdaught', '##rdclanging', '##rdfngh', '##rdfought', '##rdfoughtfor', '##rdiminishing', '##rdough', '##rdraught', '##rdrumbursting', '##rdscruffy', '##rdstubbl', '##rdstubbly', '##rdstumbling', '##rflung', '##rfullylaugh', '##rfulthough', '##rfwrought', '##rgggggggggggghhhhhhhhhhhhhh', '##rggggggggggghhh', '##rggggggggghhhhhh', '##rgggggggghhhhhhhhhhhhhh', '##rggggggghhhhhhhh', '##rgggggghhhh', '##rgggggghhhhhhhhh', '##rgggggghhllllhh', '##rgggggh', '##rggggghhhh', '##rggggghhhhhhh', '##rgggghhh', '##rgggghhhh', '##rgggghhhhh', '##rgggghhhhhh', '##rgggghhhhhhhh', '##rgggh', '##rggghh', '##rggghhh', '##rggghhhh', '##rggghhhhh', '##rgghghg', '##rgghh', '##rgghhh', '##rgghhhh', '##rgghhhhh', '##rgghhhhhhhhh', '##rgghhhhhhhhhhhh', '##rggooooooharghh', '##rghang', '##rghbugg', '##rghh', '##rghhd', '##rghhh', '##rghhhh', '##rghhhhh', '##rghnononoaarghbugg', '##rghul', '##rghum', '##rghus', '##rgiz', '##rgranddaught', '##rgwannawannaaaagongongonaargggaaaa', '##rgywhil', '##rhang', '##rhanging', '##rhumbl', '##ribiths', '##riffith', '##rightcough', '##rightjust', '##rightjusta', '##rightjustar', '##rightjustaro', '##rightjustarou', '##rightjustaroun', '##rightjustaround', '##rightjustaroundt', '##rightjustaroundth', '##rightjustb', '##rightjustp', '##rightjustpa', '##rightjustpas', '##rightjustpast', '##rightjustpastt', '##rightjustpastth', '##rikalbumbcrunch', '##riliz', '##rillywhat', '##rilosqwis', '##rilosqwism', '##rilosqwist', '##ringlywhit', '##ringsubj', '##rinkinghangov', '##riouspuzzl', '##rippydizzl', '##rippythings', '##riqh', '##rissizz', '##rissrissizz', '##riumbutor', '##rizz', '##rizzb', '##rizzi', '##rizzit', '##rizzk', '##rizzl', '##rizzy', '##rizzz', '##rizzzz', '##rjor', '##rjorx', '##rjorxa', '##rjorxas', '##rjoy', '##rjur', '##rjurg', '##rjuring', '##rjury', '##rkbough', '##rkdaught', '##rkrough', '##rlalmostcatatonicwithjoy', '##rlclutching', '##rldanythingthat', '##rlogicallywhy', '##rlugg', '##rlugga', '##rluggau', '##rlung', '##rlywhit', '##rmajorc', '##rmajorca', '##rmajorcap', '##rmajorcapt', '##rmajorcapta', '##rmajorcaptai', '##rmajorcaptain', '##rmajorcaptainwh', '##rmajorcaptainwha', '##rmajorcaptainwhat', '##rmallywhat', '##rmandfuzzy', '##rmathrong', '##rmindgoallfuzzy', '##rmpouch', '##rmstrong', '##rmthumb', '##robablywh', '##rocuffs', '##rofthought', '##rogbugging', '##romborough', '##romizzy', '##rong', '##rongi', '##rongo', '##rongwrong', '##rosoliz', '##rossdraught', '##rosshatching', '##rotchhang', '##rotchhugging', '##rouch', '##rouching', '##rough', '##roughlyobj', '##rouphugging', '##rowngrizzly', '##rphywh', '##rpong', '##rrainmatching', '##rrang', '##rranging', '##rrazzo', '##rrgggggggggggghhhhhhhhhhhhhh', '##rrggggggggggghhh', '##rrggggggggghhhhhh', '##rrgggggggghhhhhhhhhhhhhh', '##rrggggggghhhhhhhh', '##rrgggggghhhh', '##rrgggggghhhhhhhhh', '##rrgggggghhllllhh', '##rrgggggh', '##rrggggghhhh', '##rrggggghhhhhhh', '##rrgggghhh', '##rrgggghhhh', '##rrgggghhhhh', '##rrgggghhhhhh', '##rrgggghhhhhhhh', '##rrgggh', '##rrggghh', '##rrggghhh', '##rrggghhhh', '##rrggghhhhh', '##rrgghh', '##rrgghhh', '##rrgghhhh', '##rrgghhhhh', '##rrgghhhhhhhhh', '##rrghh', '##rrghhd', '##rrghhh', '##rrghhhh', '##rrghhho', '##rrghhhoo', '##rrghhhooo', '##rrghhhoooo', '##rrghhhooooh', '##rriqh', '##rrrgggggggggggghhhhhhhhhhhhhh', '##rrrggggggggggghhh', '##rrrggggggggghhhhhh', '##rrrgggggggghhhhhhhhhhhhhh', '##rrrggggggghhhhhhhh', '##rrrgggggghhhh', '##rrrgggggghhhhhhhhh', '##rrrgggggh', '##rrrggggghhhh', '##rrrggggghhhhhhh', '##rrrgggghhh', '##rrrgggghhhh', '##rrrgggghhhhh', '##rrrgggghhhhhh', '##rrrgggghhhhhhhh', '##rrrgggh', '##rrrggghh', '##rrrggghhh', '##rrrggghhhh', '##rrrggghhhhh', '##rrrggghhhhhh', '##rrrggghhhhhhh', '##rrrgghh', '##rrrgghhh', '##rrrgghhhh', '##rrrgghhhhhhhhh', '##rrrghh', '##rrrghhh', '##rrrghhhh', '##rrrrgggggggggggghhhhhhhhhhhhhh', '##rrrrggggggggggghhh', '##rrrrggggggggghhhhhh', '##rrrrgggggggghhhhhhhhhhhhhh', '##rrrrggggggghhhhhhhh', '##rrrrgggggghhhh', '##rrrrgggggghhhhhhhhh', '##rrrrgggggh', '##rrrrggggghhhh', '##rrrrggggghhhhhhh', '##rrrrgggghhhhh', '##rrrrgggghhhhhh', '##rrrrgggghhhhhhhh', '##rrrrggghhh', '##rrrrggghhhhhh', '##rrrrgghhhh', '##rrrrgghhhhhhhhh', '##rrrrghhhh', '##rrrrrgggggggggggghhhhhhhhhhhhhh', '##rrrrrggggggggggghhh', '##rrrrrgggggggghhhhhhhhhhhhhh', '##rrrrrggggggghhhhhhhh', '##rrrrrgggggghhhh', '##rrrrrgggggh', '##rrrrrggggghhhh', '##rrrrrgggghhhhhh', '##rrrrrgggghhhhhhhh', '##rrrrrggghhh', '##rrrrrgghhhh', '##rrrrrrgggggggggggghhhhhhhhhhhhhh', '##rrrrrrggggggggggghhh', '##rrrrrrgggggggghhhhhhhhhhhhhh', '##rrrrrrggggggghhhhhhhh', '##rrrrrrgggggghhhh', '##rrrrrrggggghhhh', '##rrrrrrgggghhhhhhhh', '##rrrrrrgghhhh', '##rrrrrrrgggggggggggghhhhhhhhhhhhhh', '##rrrrrrrggggggggggghhh', '##rrrrrrrgggggggghhhhhhhhhhhhhh', '##rrrrrrrggggggghhhhhhhh', '##rrrrrrrgggghhhhhhhh', '##rrrrrrrgghhhh', '##rrrrrrrrgggggggggggghhhhhhhhhhhhhh', '##rrrrrrrrgggggggghhhhhhhhhhhhhh', '##rrrrrrrrgghhhh', '##rrrrrrrrrgggggggggggghhhhhhhhhhhhhh', '##rrrrrrrrrgggggggghhhhhhhhhhhhhh', '##rrrrrrrrrgghhhh', '##rryplumb', '##rrysnatching', '##rrywizzard', '##rsclutching', '##rscrubbing', '##rsgrizzl', '##rshluggin', '##rshrugging', '##rsluggish', '##rsmashing', '##rssmuggl', '##rsthoroughly', '##rtblumb', '##rthought', '##rthumb', '##rtiliz', '##rtrang', '##rttugging', '##rtyaughtsix', '##rtycrashing', '##rubb', '##rubbing', '##rubby', '##rucksmashing', '##ruffy', '##rugg', '##ruggl', '##ruggling', '##rugsmuggl', '##rugsmuggling', '##rulywhit', '##rumb', '##rumbl', '##rumbu', '##rushing', '##rutching', '##rutchsmashing', '##rutiliz', '##ruuugh', '##ruzz', '##rwaythingy', '##rwrought', '##rylaughing', '##ryplumb', '##ryshrugg', '##rysnatching', '##rystalliz', '##rything', '##rythingjust', '##rythingwatching', '##rywh', '##rywizzard', '##s', '##sacucumb', '##sarghh', '##sawpuzzl', '##sblushing', '##sbrough', '##schlubb', '##sciviliz', '##sclubby', '##sclutching', '##sconjuring', '##scratching', '##scrubb', '##scrubbi', '##scrubbin', '##scrubbing', '##scruffy', '##scuffs', '##scuitacquisition', '##sdraught', '##sfizzl', '##sfjordu', '##sgranddaught', '##sgrizzl', '##sgrizzly', '##sguzzl', '##sh', '##shanging', '##shatching', '##shbang', '##shcaught', '##shclubb', '##shhung', '##shhungr', '##shhungry', '##shing', '##shingmuch', '##shizzl', '##shluggi', '##shluggin', '##shlyscrubb', '##shmong', '##shrugg', '##shrugging', '##shscrubb', '##shslaught', '##shsplashing', '##shthought', '##shuff', '##shuffl', '##shuffling', '##shwashing', '##sidowrong', '##siliz', '##sintopingpongb', '##sizz', '##sizzl', '##sizzling', '##slaught', '##sluggi', '##sluggis', '##sluggish', '##slumb', '##slung', '##smashing', '##smuggl', '##smuggling', '##snatching', '##sobj', '##sohumbl', '##sojoyful', '##soliz', '##sonwishing', '##sought', '##spatching', '##splashing', '##spoliz', '##sprang', '##spuzzl', '##squish', '##squishsquish', '##sqw', '##srissizz', '##srumbl', '##ssciviliz', '##ssdraught', '##sshatching', '##sshrugg', '##ssiliz', '##ssizz', '##ssmuggl', '##sspuzzl', '##ssrissizz', '##sstrongh', '##sstruggl', '##sstumbl', '##ssubjug', '##ssywhip', '##ssywhipp', '##staatspoliz', '##stabiliz', '##stablishing', '##stacuffs', '##stalliz', '##stcatatonicwithjoy', '##sthanging', '##sthoroughly', '##sticuffs', '##stingugh', '##stinguishing', '##stinywhydid', '##stizzi', '##stlywhit', '##stpizz', '##stpizza', '##strang', '##straught', '##strong', '##strongh', '##struggl', '##struggling', '##stsconjuring', '##stscrubb', '##stsgrizzly', '##stsmashing', '##stsunplung', '##stthumb', '##stubb', '##stubbl', '##stubbly', '##stubbo', '##stubbor', '##stubborn', '##stuff', '##stumbl', '##stumbling', '##stvanquish', '##styjungl', '##styliz', '##subb', '##subj', '##subju', '##subjug', '##sugg', '##sughw', '##sunplung', '##swizzl', '##swrongwithm', '##swung', '##sybugg', '##sylizzy', '##sywhiffling', '##sywhip', '##sywhipp', '##t', '##taatspoliz', '##tabiliz', '##tabith', '##tablishing', '##taboliz', '##tacquisition', '##tacuffs', '##talliz', '##tarsthoroughly', '##tasobj', '##tatonicwithjoy', '##taught', '##tblumb', '##tcatatonicwithjoy', '##tchcoughing', '##tchhang', '##tchhugging', '##tching', '##tchlizard', '##tchsmashing', '##tclubb', '##tcough', '##tcouldgowrong', '##tdoanythingthati', '##tdoanythingthatin', '##tdoanythingthatinv', '##tdoanythingthatinvo', '##tdoanythingthatinvol', '##tdoanythingthatinvolv', '##tdraughts', '##tfjord', '##tflashing', '##tfluffy', '##tfrazzl', '##tfumbl', '##tgoingoutclubbi', '##tgowrong', '##tgranddaught', '##tguninjur', '##th', '##thafugg', '##thanging', '##thbrushing', '##thcatching', '##thdubb', '##thicallywhat', '##thing', '##thinganything', '##thinganythingb', '##thinganythingbu', '##thinganythingbut', '##thinganythingfought', '##thinganythingh', '##thinganythingha', '##thinganythinghapp', '##thinganythingjust', '##thinganythingth', '##thinganythingtha', '##thinganythingthat', '##thinganythingw', '##thinganythingwo', '##thinganythingwou', '##thinganythingwoul', '##thinganythingwould', '##thingfought', '##thinghang', '##thinghangr', '##thinghangro', '##thinghangrop', '##thinglashing', '##thingmuch', '##thingstrang', '##thjus', '##thlaugh', '##thlaughingh', '##thologiz', '##thorough', '##thoroughly', '##though', '##thought', '##thqw', '##thrashing', '##throng', '##through', '##thstruggl', '##ththumbs', '##thtouch', '##thubby', '##thumb', '##thwashing', '##thwashingm', '##tickatnaught', '##tickluggin', '##ticuffs', '##tifrizz', '##tifulthough', '##tiliz', '##tillcrouching', '##tillhanging', '##tillsizzling', '##tillsluggish', '##tillstruggling', '##tingugh', '##tinguishing', '##tinumblond', '##tinywhydid', '##tiswrongwithm', '##tizzi', '##tjumbl', '##tjungl', '##tlyacquir', '##tlywhit', '##tmajor', '##tmumbling', '##tnaught', '##tographjust', '##tomachlizards', '##tonicwithjoy', '##tophugging', '##topingpongb', '##toqq', '##tosugg', '##tothqw', '##touch', '##touchh', '##touching', '##tough', '##tpizz', '##tpong', '##tpublishingcom', '##trang', '##tranquiliz', '##traphanging', '##traught', '##traumfjord', '##trazzi', '##trazzin', '##trazzini', '##trillywhat', '##trilosqwism', '##trilosqwist', '##tringsubj', '##trocuffs', '##trong', '##trucksmashing', '##truggl', '##truggling', '##trulywhit', '##trumbl', '##tsconjuring', '##tscrubb', '##tscuffs', '##tsgrizzly', '##tsmashing', '##tsobj', '##tspoliz', '##tsstruggl', '##tsughw', '##tsunplung', '##tthumb', '##ttoqq', '##ttugging', '##ttumbling', '##tubb', '##tubby', '##tuff', '##tuffjust', '##tugg', '##tugging', '##tumbl', '##tumbling', '##tumfuzz', '##tungthough', '##tupidgrubbs', '##turong', '##tvanquish', '##tvanquishing', '##twanging', '##twiththumbs', '##twizzl', '##tyaughtsix', '##tycrashing', '##tyjoha', '##tyjungl', '##tyliz', '##tyrbjor', '##tzhugh', '##u', '##uaough', '##uardstumbling', '##ubang', '##ubb', '##ubby', '##ubciviliz', '##ubj', '##ublishing', '##ubsubb', '##ububbl', '##uccumb', '##uch', '##uchang', '##uchthumb', '##uckborough', '##uckfuzz', '##uckobj', '##ucksmashing', '##ucumb', '##udrumbl', '##uff', '##uffadjust', '##uffjust', '##uffy', '##uffywh', '##ufghh', '##ugchugchugging', '##ugchugging', '##ugg', '##ugggh', '##uggghh', '##uggghhh', '##ugghh', '##ugghhh', '##ugghhhh', '##ugghhw', '##uggi', '##ugging', '##uggl', '##ugh', '##ughandtumbl', '##ughw', '##ugsmashing', '##ugsmuggl', '##ugsmuggling', '##uishing', '##uitacquisition', '##ujumb', '##uldgowrong', '##uldugg', '##ulldugg', '##ullingugh', '##ullplugg', '##ullswung', '##ullylaugh', '##ullywh', '##ulogiz', '##ulrazzaq', '##ulthough', '##ulung', '##ulywhit', '##umanssubjugat', '##umb', '##umbju', '##umbjus', '##umbjust', '##umbl', '##umblo', '##umblon', '##umblond', '##umbloo', '##umblood', '##umbly', '##umbojumbo', '##umbu', '##umbug', '##umbum', '##umbur', '##umburg', '##umfjor', '##umfjord', '##umfuzz', '##ummydaught', '##umong', '##umpjang', '##umrubb', '##ung', '##ungrumbli', '##ungswizzl', '##ungthough', '##uninjur', '##unjong', '##unkjangl', '##unlightjust', '##unplung', '##unttumbling', '##uphugging', '##upidgrubbs', '##uqx', '##urdough', '##urghang', '##urghhhhh', '##urghul', '##uriouspuzzl', '##urmindgoallfuzzy', '##urong', '##urphywh', '##urrrrrrgggggghhhh', '##ush', '##ushing', '##uspuzzl', '##ussywhip', '##ussywhipp', '##ustvanquish', '##usylizzy', '##utching', '##utchsmashing', '##utclubb', '##uthafugg', '##uthbrushing', '##uthjus', '##uthwashingm', '##uthwashingmo', '##utifulthough', '##utiliz', '##utjumbl', '##utographjust', '##utosugg', '##utouchh', '##utrumbl', '##utyjoha', '##utyjohan', '##utyjohann', '##utyjohanna', '##uugggh', '##uuggghh', '##uuggghhh', '##uugghh', '##uugh', '##uughh', '##uughhh', '##uurrrrrrgggggghhhh', '##uuugggh', '##uuugh', '##uuught', '##uuughty', '##uuurrrrrrgggggghhhh', '##uuuurrrrrrgggggghhhh', '##uuuuurrrrrrgggggghhhh', '##uuuuuurrrrrrgggggghhhh', '##uuzz', '##uwaqqit', '##uyscrubb', '##uzz', '##uzzzzz', '##uzzzzzzzzzz', '##v', '##vanaugh', '##vanquish', '##vanquishing', '##vaugh', '##vaughn', '##vbrought', '##viliz', '##vilydrugg', '##vingchompingscratching', '##vishing', '##vrong', '##vrongo', '##w', '##waarggghh', '##wallhanging', '##wanging', '##wannaaaagongongonaarggga', '##wannawannaaaagongongonaargggaaaa', '##waqqit', '##warfwrought', '##washing', '##watching', '##waything', '##waythingy', '##wbjw', '##wdaught', '##wdonmcqui', '##wfought', '##wh', '##whackjob', '##wishing', '##withjoy', '##withstrang', '##withthumbs', '##wizz', '##wizza', '##wizzar', '##wizzard', '##wizzf', '##wizzl', '##wjor', '##wjord', '##wjorda', '##wjordan', '##wlyacquir', '##wngrizzly', '##wough', '##wpuzzl', '##wrong', '##wrongw', '##wrongwith', '##wrongwithm', '##wrongwrong', '##wrongwrongwrongwrong', '##wrough', '##wrought', '##wsarghh', '##wuffy', '##wung', '##wuzz', '##wwaarggghh', '##wwbjw', '##wwdonmcqui', '##wwrong', '##wwwaarggghh', '##wything', '##x', '##xbubbl', '##xchang', '##xchanging', '##xcuff', '##xcuffs', '##xibubbl', '##xilliumbut', '##xtinguishing', '##xwithstrang', '##xywhi', '##xywhit', '##y', '##yacquir', '##yarrgghhh', '##yaught', '##yaughts', '##yaughtsi', '##yaughtsix', '##ybugg', '##ybugh', '##ybumbl', '##ybuzz', '##ycoughc', '##ycoughcantcough', '##ycrashing', '##ydaught', '##ydisfjordu', '##ydisfjordur', '##ydisfjordurc', '##ydisfjordurco', '##ydisfjordurcom', '##ydizzl', '##ydough', '##ydrugg', '##ydumbly', '##yflashing', '##yfought', '##yfoughto', '##yfoughtoff', '##yfuzz', '##ygh', '##ygho', '##yghos', '##yghost', '##ygrubb', '##ygrubbi', '##ygrubbin', '##ygrubbing', '##yhugging', '##yizzy', '##yjoha', '##yjohnghos', '##yjung', '##yjungl', '##ylaugh', '##ylaughing', '##yliz', '##ylizzy', '##ymaugh', '##ymboliz', '##ymuzz', '##ymuzzl', '##ynaught', '##ynngh', '##yobj', '##yonlydaught', '##yoohughh', '##yourmindgoallfuzzy', '##youtouchh', '##yplumb', '##ypzzz', '##yrbjor', '##yrrang', '##ysclubby', '##yscrubb', '##yshrugg', '##ysnatching', '##ystalliz', '##ystyliz', '##yswung', '##ythicallywhat', '##ything', '##ythingfought', '##ythingjust', '##ythologiz', '##ywh', '##ywhi', '##ywhich', '##ywhiff', '##ywhiffl', '##ywhiffling', '##ywhil', '##ywhip', '##ywhipp', '##ywhis', '##ywhisk', '##ywhit', '##ywizzard', '##yyarrgghhh', '##yyyarrgghhh', '##z', '##zadajizz', '##zhugh', '##zing', '##zozzzzztapp', '##zumb', '##zumba', '##zywh', '##zywha', '##zywhat', '##zz', '##zzcumb', '##zzy', '##zzz', '##zzzz', '##zzzzz', '##zzzzzt', '##zzzzzta', '##zzzzztapp', '##zzzzzy', '##zzzzzzzz', '##zzzzzzzzzz', '##zzzzzzzzzzzz', '##zzzzzzzzzzzzz', '[CLS]', '[MASK]', '[PAD]', '[SEP]', '[UNK]', 'a', 'aaaaaaaaaaaaaagggggggggggghhhhhhhhhhhh', 'aaaaaaarrrrrrrggggggggggghhh', 'aaaaaaggggggghhhhhhhhh', 'aaaaaagggggghhhhhh', 'aaaaaarrrrggggggggghhhhhh', 'aaaaaarrrrggggghhhhhhh', 'aaaaaarrrrgggghhhhh', 'aaaaaggggggghhhhhhhhh', 'aaaaaggghhh', 'aaaaagghh', 'aaaaarrrggghhhhhhh', 'aaaaarrrrgggggghhhhhhhhh', 'aaaaarrrrgggghhhhh', 'aaaaarrrrrgggghhhhhh', 'aaaaarrrrrrrggggggghhhhhhhh', 'aaaagggggghhhhhh', 'aaaaggghhh', 'aaaammmbush', 'aaaargwannawannaaaagongongonaargggaaaa', 'aaaarrgghhh', 'aaaarrghh', 'aaaarrrgggghhhh', 'aaaarrrrggghhhhhh', 'aaagghh', 'aaagghhh', 'aaahhgghh', 'aaarghhhh', 'aaarrgghh', 'aaarrghhhooooh', 'aaarrrgggghhh', 'aaarrrggghhh', 'aaarrrggghhhhhhh', 'aagghh', 'aarrggghhh', 'aarrgghh', 'aarrgghhhhh', 'aarrrggghh', 'aarrrggghhh', 'aarrrrrggghhh', 'aaughhhh', 'ab', 'abang', 'abangh', 'abdulrazzaq', 'abj', 'abl', 'abo', 'aboa', 'aboar', 'aboard', 'abolishing', 'abom', 'abomb', 'abomi', 'abomin', 'abomina', 'abominab', 'abominabl', 'abominably', 'abominal', 'abominall', 'abominally', 'abominat', 'abominati', 'abominatio', 'abomination', 'abominativ', 'abomino', 'abominou', 'abominous', 'abominousl', 'abominously', 'abong', 'abou', 'abouk', 'abouki', 'aboukir', 'aboun', 'abound', 'about', 'aboutanywh', 'aboutstrong', 'abouu', 'abouut', 'abouuta', 'abouuu', 'abouuut', 'abouuuu', 'abouuuuu', 'abouuuuut', 'abov', 'abruzz', 'abruzzi', 'abruzzo', 'abubb', 'abubbl', 'abubbli', 'abubblin', 'abubbling', 'abuzz', 'accomplishing', 'acqui', 'acquir', 'acquiring', 'adjur', 'adjus', 'adjust', 'adjusting', 'adowrongwrong', 'aff', 'afgh', 'afgha', 'afghan', 'afghani', 'afghanis', 'afghanist', 'afghanista', 'afghanistan', 'afghu', 'afghul', 'afghuli', 'afghulis', 'againhiphugg', 'agggghhhh', 'agggh', 'aggghh', 'aggghhhhh', 'agghhh', 'agghhhhhhhhhhhh', 'aghh', 'aghhh', 'aghhhh', 'aghhhhhhhhhhhhh', 'ahhouaough', 'ahhrrggghh', 'ahpuch', 'ajohf', 'ajor', 'ajors', 'ajorsi', 'akhough', 'alallalallarumbakamandalindorburum', 'aldiough', 'allaghhh', 'almuwaqqit', 'along', 'alrightcough', 'although', 'alumb', 'alumbr', 'alumbra', 'alumbrad', 'alumbrado', 'alumbrados', 'ambush', 'ambushing', 'among', 'amphith', 'amumbling', 'anbangbang', 'andaghh', 'andjoong', 'andzzzzztit', 'ang', 'anguishing', 'antifrizz', 'anuzz', 'anything', 'anythinganything', 'anythingstrang', 'anywh', 'apologiz', 'appologiz', 'apppologiz', 'archang', 'argghghg', 'argghh', 'arghh', 'armstrong', 'armthumb', 'arrang', 'arranging', 'arrgggghhhh', 'arrgggh', 'arrggghh', 'arrggghhhh', 'arrgghh', 'arrgghhh', 'arrgghhhh', 'arrghh', 'arrghhh', 'arrrgggh', 'arrrggghh', 'arrrggghhh', 'arrrggghhhh', 'arrrggghhhhh', 'arrrgghh', 'arrrgghhh', 'arrrgghhhh', 'arrrghh', 'arrrrgghhhhhhhhh', 'arrrrghhhh', 'arrrrrgggggh', 'arrrrrgghhhh', 'arrrrrrggggghhhh', 'arrrrrrrrrgggggggggggghhhhhhhhhhhhhh', 'arrrrrrrrrgggggggghhhhhhhhhhhhhh', 'arumb', 'asplashing', 'astruggling', 'augg', 'augh', 'aughh', 'aughhh', 'aughhhh', 'aughp', 'aughpl', 'aught', 'aughth', 'autographjust', 'autosugg', 'auughhh', 'awrongwrongwrongwrong', 'azz', 'azza', 'azzar', 'azzara', 'azzay', 'azzayy', 'azzayya', 'azzayyat', 'azzayyati', 'azzi', 'azziz', 'azzu', 'azzul', 'azzulu', 'azzuluf', 'b', 'babyoohughh', 'babysnatching', 'backjord', 'backjorda', 'backjordan', 'backlashing', 'backlaughing', 'bajor', 'bajora', 'bajoran', 'ballintubb', 'bamborough', 'bang', 'bangbang', 'bangbangbang', 'banging', 'banlumb', 'barong', 'barouch', 'barrywizzard', 'bashing', 'batching', 'baugh', 'baughy', 'bbj', 'bbrought', 'bhangbhang', 'bhangbhangd', 'bhangbhangdu', 'bhangbhangduc', 'bigbang', 'bighang', 'bigjob', 'bigjobs', 'billybumbl', 'binturong', 'birchboughs', 'biscuitacquisition', 'bitchlizard', 'bitfrazzl', 'bizz', 'bizzi', 'bjor', 'bjork', 'bjorn', 'bjorng', 'bjorngu', 'bjorngun', 'bjorngunn', 'bjorngunna', 'bjorngunnar', 'bjorngunnars', 'bjorngunnarso', 'bjorngunnarson', 'blizz', 'blizza', 'blizzar', 'blizzard', 'bloodgushing', 'bloogynaughts', 'blowjob', 'blubb', 'blumbl', 'blumblu', 'blumblum', 'blushing', 'bluugh', 'bodyhugging', 'bodysnatching', 'bodyswung', 'boliz', 'bolizi', 'bolizia', 'bonjur', 'bookchang', 'bopmugg', 'borough', 'boroughs', 'bothlaugh', 'bouch', 'bough', 'boughs', 'bought', 'boyjohnghos', 'boyjohnghost', 'boysclubby', 'bozozzzzztapp', 'braininjur', 'brainwashing', 'brannaugh', 'braught', 'braughto', 'braughton', 'brazz', 'brazza', 'brazzi', 'brizz', 'brizzi', 'brizzil', 'bromborough', 'brough', 'brougha', 'brougham', 'brought', 'browngrizzly', 'brushing', 'bu', 'bubb', 'bubba', 'bubbi', 'bubbl', 'bubbling', 'bubby', 'bububbl', 'buch', 'bucha', 'buchaa', 'buchaar', 'buchaard', 'buchan', 'buchana', 'buchanan', 'buchann', 'buchanna', 'buchannan', 'buchar', 'buchh', 'buchho', 'buchhol', 'buchholt', 'buchholtz', 'bucho', 'buchog', 'buchon', 'buchw', 'buchwa', 'buchwal', 'buchwald', 'buck', 'buckju', 'buckjum', 'buckjump', 'bucksh', 'bucksho', 'buckshot', 'buckshoth', 'buckshothu', 'buckshothur', 'buckshothurr', 'buckshothurry', 'buckwh', 'buff', 'bugg', 'bugging', 'buggywh', 'buggywhi', 'buggywhich', 'buggywhip', 'bugh', 'bugsmashing', 'bujumb', 'bujumbu', 'bujumbur', 'bujumbura', 'bumbl', 'bumbling', 'bumbu', 'bumbud', 'bumbudd', 'bumbuddy', 'burghul', 'burong', 'bush', 'bushing', 'bushrang', 'bushwh', 'bushwha', 'bushwhack', 'bushwhacking', 'busylizzy', 'but', 'butchang', 'butjumbl', 'buttmajor', 'buttmajorl', 'buttmajorly', 'butugh', 'buzz', 'buzzbuzz', 'buzzbuzzbuzz', 'buzzing', 'buzzzzz', 'buzzzzzzzzzz', 'byrrang', 'byrranga', 'bzzz', 'bzzzt', 'bzzzz', 'bzzzzz', 'bzzzzzt', 'c', 'cabubb', 'cabubba', 'canlubang', 'cantgowrong', 'capuchin', 'carumb', 'carumba', 'catching', 'caugh', 'caught', 'cavanaugh', 'cccouch', 'ch', 'chalkywhit', 'chang', 'changing', 'changingthough', 'charmpouch', 'childsnatching', 'choirboybugg', 'chojoh', 'chough', 'chubb', 'chubby', 'chuch', 'chuff', 'chuffing', 'chugchugchugging', 'chugg', 'chugging', 'chugh', 'chughi', 'chughis', 'chughiss', 'chughissc', 'chughissch', 'chughisschu', 'chughisschug', 'chumb', 'chumba', 'chumbaw', 'chumbawa', 'chumbawamb', 'chumbawamba', 'cimbulung', 'civiliz', 'civiliza', 'civilizat', 'civilizati', 'civilizatio', 'civilization', 'clangbang', 'clanging', 'clashing', 'clawsarghh', 'cliffhang', 'cliffhanging', 'cliquish', 'clockwatching', 'clothinglashing', 'clubb', 'clubbing', 'clubby', 'clubbys', 'clumpjang', 'clumpjangl', 'clung', 'clunkjangl', 'clutching', 'co', 'cobb', 'cobbl', 'cocizzy', 'cock', 'cockjo', 'cockjock', 'cockp', 'cockpi', 'cockpit', 'cockpo', 'cockpoi', 'cockpoin', 'cockpoint', 'cocumb', 'coff', 'coffincouch', 'coh', 'col', 'colindrikalbumbcrunch', 'columb', 'columba', 'columbar', 'columbari', 'columbariu', 'columbarium', 'columbi', 'columbia', 'columbin', 'columbina', 'columbo', 'columbu', 'columbus', 'com', 'comb', 'comba', 'combat', 'combath', 'combatha', 'combathar', 'combathard', 'combathi', 'combathis', 'combi', 'combin', 'combing', 'combu', 'combus', 'combust', 'combusti', 'combustib', 'combustibi', 'combustibil', 'combustibili', 'combustibilit', 'combustibility', 'combustibl', 'combusting', 'combustio', 'combustion', 'combustiv', 'comf', 'comfo', 'comfor', 'comfort', 'comforth', 'comforting', 'comfy', 'coming', 'comingstrong', 'comm', 'commong', 'commongr', 'commongro', 'commongrou', 'commongroun', 'commonground', 'commu', 'commun', 'communi', 'communic', 'communica', 'communicab', 'communicabl', 'communican', 'communicant', 'communicants', 'communicat', 'communicati', 'communicatin', 'communicating', 'communicatio', 'communication', 'communicativ', 'communicuff', 'communio', 'communion', 'communiong', 'communiongr', 'communiongri', 'communiqu', 'communis', 'communism', 'communist', 'communit', 'communiti', 'community', 'communitybrought', 'communitythough', 'commut', 'commuting', 'comp', 'companywhich', 'compl', 'con', 'conajohar', 'conajohara', 'conc', 'conch', 'cond', 'condi', 'condig', 'condign', 'condignl', 'condignly', 'condim', 'condin', 'condit', 'conditi', 'conditio', 'condition', 'condo', 'condom', 'condu', 'conduc', 'conduci', 'conduciv', 'conduct', 'conducting', 'condui', 'conduit', 'condum', 'conf', 'confi', 'confic', 'confict', 'conficts', 'confid', 'config', 'configu', 'configur', 'configura', 'configurat', 'configurati', 'configuratio', 'configuration', 'confin', 'confir', 'confirm', 'confirming', 'confis', 'confisc', 'confisca', 'confiscam', 'confiscama', 'confiscamat', 'confiscat', 'confiscating', 'confu', 'confuc', 'confuci', 'confucia', 'confucian', 'confuciu', 'confucius', 'confus', 'confusing', 'cong', 'congr', 'congra', 'congrat', 'congratch', 'congrating', 'congrats', 'congratu', 'congratul', 'congratula', 'congratulat', 'congratulati', 'congratulating', 'congratulatio', 'congratulation', 'congratulations', 'congrau', 'congraud', 'congrauda', 'congraudal', 'congraudala', 'congraudalat', 'congraudalati', 'congraudalatio', 'congraudalation', 'congraudalations', 'conj', 'conju', 'conjug', 'conjuga', 'conjugal', 'conjugat', 'conjugati', 'conjugating', 'conjugatio', 'conjugation', 'conjugations', 'conjun', 'conjunc', 'conjunct', 'conjuncti', 'conjunctif', 'conjunctifi', 'conjunctio', 'conjunction', 'conjunctiv', 'conjunctiva', 'conjunctivi', 'conjunctivit', 'conjunctiviti', 'conjunctivitis', 'conjunctu', 'conjunctur', 'conjunt', 'conjunta', 'conjur', 'conjuring', 'conn', 'connaught', 'conqu', 'cons', 'consc', 'consci', 'conscio', 'consciou', 'conscioun', 'conscious', 'conscioush', 'consciousha', 'conscioushad', 'consciousn', 'conscr', 'conscri', 'conscrip', 'conscript', 'consi', 'consid', 'consig', 'consigl', 'consigli', 'consiglio', 'consign', 'consigning', 'consignm', 'consigu', 'consip', 'consipr', 'consipra', 'consiprat', 'consiprati', 'consipratio', 'consipration', 'consiprationa', 'consiprational', 'consiprationall', 'consiprationally', 'consis', 'consist', 'consisting', 'consp', 'conspi', 'conspic', 'conspicu', 'conspicuo', 'conspicuou', 'conspicuous', 'conspir', 'conspira', 'conspirac', 'conspiraci', 'conspiracy', 'conspirat', 'conspirato', 'conspirator', 'conspiratori', 'conspiratoria', 'conspiratorial', 'conspiratoriall', 'conspiratorially', 'conspirators', 'conspiring', 'const', 'consu', 'consul', 'consult', 'consulting', 'consulwh', 'consulwho', 'consum', 'consuming', 'consump', 'consumpt', 'consumpti', 'consumptio', 'consumption', 'consumptiv', 'cont', 'conti', 'contig', 'contigo', 'contigu', 'contiguo', 'contiguou', 'contiguous', 'contin', 'continu', 'conv', 'conw', 'conwa', 'conway', 'conwi', 'conwin', 'conwinc', 'conwy', 'coolasacucumb', 'cop', 'copp', 'copy', 'cou', 'couch', 'couck', 'coucko', 'couckoo', 'couckoos', 'coug', 'couga', 'cougar', 'cough', 'coughcough', 'coughing', 'coughlaugh', 'cougr', 'coul', 'could', 'couldanything', 'couldlaugh', 'couls', 'coulso', 'coulson', 'coult', 'coum', 'couma', 'coumad', 'coumadi', 'coumadin', 'coun', 'counc', 'counci', 'council', 'cound', 'counda', 'coundai', 'coundais', 'coundaisy', 'counh', 'counhi', 'counhij', 'counl', 'counld', 'counldn', 'counldnt', 'couns', 'count', 'counth', 'couo', 'couoh', 'coup', 'coupl', 'cour', 'coura', 'courag', 'couran', 'courant', 'courg', 'couri', 'cours', 'coursh', 'court', 'courth', 'courtho', 'courthou', 'courthous', 'courtsh', 'courtshi', 'courtship', 'courty', 'courtya', 'courtyar', 'courtyard', 'courv', 'courvo', 'courvoi', 'courvois', 'courvoisi', 'courz', 'cous', 'cousc', 'cousco', 'couscou', 'couscous', 'cousi', 'cousin', 'cousing', 'coust', 'cout', 'couth', 'couthi', 'couti', 'coutu', 'coutur', 'couty', 'coutya', 'coutyar', 'coutyard', 'coutyards', 'couv', 'couvi', 'couvir', 'couvr', 'cov', 'coz', 'cozi', 'cozy', 'crashing', 'crazz', 'crazza', 'crazzan', 'crazzank', 'crossdraught', 'crosshatching', 'crotchhang', 'crotchhugging', 'crouch', 'crouching', 'cruffy', 'crumb', 'crumbl', 'crumbling', 'crumbs', 'crushing', 'crutching', 'crutchsmashing', 'crystalliz', 'cubb', 'cubba', 'cubbar', 'cubbard', 'cubbards', 'cubbi', 'cubbin', 'cubbins', 'cubby', 'cubbyh', 'cubbyho', 'cubbyhol', 'cucumb', 'cuff', 'cuffadjust', 'cuffadjusti', 'cuffadjustin', 'cuffadjusting', 'cuffs', 'cumb', 'cumbl', 'cumbli', 'cumblin', 'cumbling', 'curiouspuzzl', 'cush', 'cushi', 'cushing', 'cushio', 'cushion', 'cushions', 'cushy', 'd', 'daddaught', 'daddydaught', 'dang', 'darkbough', 'dashing', 'dashingmuch', 'daugh', 'daught', 'dayghost', 'dazz', 'dazzf', 'dazzfo', 'dazzfor', 'dazzford', 'dazzl', 'dazzli', 'dazzlin', 'dazzling', 'diff', 'dijung', 'dijunga', 'dijungaz', 'dillywhat', 'dimflashing', 'diminishing', 'dishwashing', 'dispatching', 'distinguishing', 'distraught', 'dizz', 'dizzi', 'dizzil', 'dizzily', 'dizzin', 'dizzy', 'dizzying', 'dj', 'dji', 'djib', 'djibo', 'djibou', 'djibout', 'djibouti', 'djim', 'djin', 'djini', 'djinn', 'djinnwh', 'djinnwhi', 'djinnwhich', 'djinnwho', 'djir', 'djor', 'djord', 'djordj', 'djordji', 'dogcaught', 'doghum', 'doghuma', 'doghuman', 'doghung', 'doghungr', 'doghungry', 'dontdoanythingthatinvolv', 'doorbanging', 'doorwaythingy', 'douch', 'douching', 'douchingt', 'douchingto', 'douchington', 'douggi', 'dough', 'doughb', 'doughba', 'doughbal', 'doughball', 'doughballs', 'doughbo', 'doughboy', 'doughbu', 'doughbur', 'doughburn', 'dow', 'dowh', 'down', 'downdraught', 'downrang', 'downstrang', 'downstuff', 'downtumbl', 'downtumbli', 'downtumblin', 'downtumbling', 'dragoncouch', 'draught', 'drinkinghangov', 'drippydizzl', 'drizzl', 'drizzling', 'drong', 'drongo', 'drough', 'drought', 'drubb', 'drubbi', 'drubbin', 'drubbing', 'drugg', 'drugging', 'druggl', 'druggla', 'drugglaz', 'drugsmuggl', 'drugsmuggling', 'drumb', 'drumbang', 'drumbanging', 'dubb', 'dubby', 'dubbya', 'duch', 'duckfuzz', 'duff', 'dugg', 'dugga', 'duggan', 'duggar', 'duggi', 'duggin', 'duggins', 'dumb', 'dumbf', 'dumbfa', 'dumbfac', 'dumbfo', 'dumbfor', 'dumbfou', 'dumbfoun', 'dumbfound', 'dumbfu', 'dumbfuck', 'dumbl', 'dumbly', 'dung', 'durghang', 'duuzz', 'dwarfwrought', 'e', 'eardrumbursting', 'edjust', 'eff', 'effo', 'effoa', 'effoan', 'effoant', 'effoanti', 'effoantin', 'effoanting', 'effoff', 'effon', 'effona', 'effonat', 'effonating', 'effont', 'effonta', 'effontat', 'effontati', 'effontatin', 'effontating', 'effor', 'effort', 'effot', 'egg', 'eggrubb', 'eggrubbi', 'eggrubbin', 'eggrubbing', 'eggs', 'eggsh', 'eggsiz', 'eggwh', 'eggwhi', 'eggwhis', 'eggwhisk', 'eggwhit', 'ehjusthigh', 'eight', 'eighth', 'eiliz', 'eith', 'elftaught', 'elfwrought', 'eliz', 'eliza', 'elizab', 'elong', 'elonga', 'elongat', 'elongating', 'emb', 'embugg', 'encumb', 'eng', 'engliz', 'enjoy', 'enjoying', 'enljoy', 'enough', 'enoughthough', 'entdraughts', 'equ', 'equa', 'equab', 'equabl', 'equably', 'equal', 'equaliz', 'equall', 'equally', 'equan', 'equani', 'equanim', 'equanimi', 'equanimit', 'equanimity', 'equanimo', 'equanimou', 'equanimous', 'equar', 'equari', 'equaria', 'equas', 'equat', 'equati', 'equating', 'equatio', 'equation', 'equato', 'equatog', 'equatogu', 'equatogui', 'equatoguin', 'equator', 'equatos', 'equi', 'equid', 'equida', 'equidi', 'equidis', 'equidist', 'equidista', 'equidistan', 'equidistanc', 'equidistant', 'equif', 'equifa', 'equifax', 'equii', 'equil', 'equila', 'equilat', 'equili', 'equilib', 'equilibr', 'equilibra', 'equilibrat', 'equilibri', 'equilibriu', 'equilibrium', 'equilin', 'equilix', 'equill', 'equilli', 'equillin', 'equim', 'equin', 'equino', 'equinoc', 'equinoct', 'equinocti', 'equinoctia', 'equinoctial', 'equinox', 'equip', 'equipm', 'equipp', 'equis', 'equit', 'equita', 'equitab', 'equitabl', 'equitably', 'equiti', 'equity', 'equiv', 'equiva', 'equival', 'equivo', 'equivoc', 'equivoca', 'equivocal', 'equivocat', 'equivocati', 'equivocatio', 'equivocation', 'errghh', 'establishing', 'estrang', 'etching', 'etchings', 'etrang', 'eugghh', 'eugghhh', 'eugghhhh', 'eugh', 'eulogiz', 'eunjong', 'ev', 'evang', 'eviljuju', 'evilwhackjob', 'ex', 'exbuff', 'exbuffa', 'exbuffal', 'exbuffalo', 'exc', 'exch', 'excha', 'excham', 'exchamp', 'exchampi', 'exchampio', 'exchampion', 'exchang', 'excidiumbut', 'excu', 'excul', 'exculp', 'exculpa', 'exculpat', 'exculpato', 'exculpator', 'exculpatory', 'excur', 'excurp', 'excurpo', 'excurpol', 'excurpola', 'excurpolar', 'excurs', 'excursi', 'excursio', 'excursion', 'excursiu', 'excursius', 'excurso', 'excursor', 'excursu', 'excursus', 'excus', 'excuth', 'excuu', 'excuuu', 'excuuus', 'excuz', 'exh', 'exha', 'exhal', 'exhaling', 'exhau', 'exhaus', 'exhaust', 'exhi', 'exhib', 'exhibi', 'exhibit', 'exhibiting', 'exhil', 'exhila', 'exhilar', 'exhilara', 'exhilaran', 'exhilarant', 'exhilarat', 'exhilarati', 'exhilarating', 'exhilaratio', 'exhilaration', 'exhis', 'exhist', 'exhisto', 'exhistor', 'exhistory', 'exhit', 'exhitm', 'exhitma', 'exhitman', 'exho', 'exhoo', 'exhook', 'exhor', 'exhorb', 'exhorba', 'exhorban', 'exhorbant', 'exhort', 'exhorting', 'exhou', 'exhous', 'exhu', 'exhum', 'exhuming', 'exhus', 'exhusb', 'exhusba', 'exhusban', 'exhusband', 'exmong', 'exmongo', 'exmongol', 'exp', 'expl', 'expla', 'explai', 'explaim', 'explaimi', 'explaimin', 'explaiming', 'explaimingi', 'explain', 'explan', 'explana', 'explanat', 'explanati', 'explanatio', 'explanation', 'explanato', 'explanator', 'explanatori', 'explanatoril', 'explanatorily', 'explanatory', 'explant', 'expli', 'explic', 'explica', 'explicab', 'explicabl', 'explicat', 'explicati', 'explicating', 'explicatio', 'explication', 'explicativ', 'explici', 'explicit', 'explicitl', 'explicitly', 'explo', 'explod', 'exploding', 'exploi', 'exploit', 'explor', 'exploring', 'explos', 'explosi', 'explosia', 'explosio', 'explosion', 'explosiv', 'explot', 'explota', 'explotan', 'explotand', 'explotando', 'expung', 'expunging', 'exqu', 'exqui', 'exquis', 'exquisi', 'exquisit', 'extinguishing', 'ey', 'ezz', 'ezza', 'ezzar', 'ezzard', 'ezzi', 'ezzy', 'f', 'familylaughing', 'fang', 'fangs', 'farflung', 'faugh', 'faught', 'fffff', 'fffffff', 'ffffffff', 'fffffffffff', 'ffffffffi', 'ffffffffj', 'fffffl', 'ffffflo', 'fffffloy', 'fffffloyd', 'fghfgh', 'fight', 'fighting', 'fightjust', 'fightstrong', 'fightthough', 'finishing', 'finnbjorn', 'fishing', 'fishmong', 'fistacuffs', 'fisticuffs', 'fistsmashing', 'fistthumb', 'fitzhugh', 'fizz', 'fizzc', 'fizzcr', 'fizzcra', 'fizzcran', 'fizzcrank', 'fizzfizz', 'fizzing', 'fizzl', 'fizzling', 'fizzy', 'fizzywh', 'fizzywha', 'fizzywhat', 'fizzywhats', 'fjor', 'fjord', 'flaghurry', 'flakywhit', 'flashbang', 'flashbangs', 'flashing', 'floorscrubbing', 'flowthrough', 'flubb', 'flubbing', 'fluffy', 'fluffywh', 'fluffywhi', 'fluffywhit', 'flung', 'flushing', 'flywh', 'flywhisk', 'foamrubb', 'followthrough', 'follywhat', 'foqw', 'fossiliz', 'fough', 'fought', 'frabjuous', 'fragiliz', 'fraught', 'frazz', 'frazzl', 'frizz', 'frizzb', 'frizzba', 'frizzbal', 'frizzball', 'frizzing', 'frizzl', 'frizzling', 'frizzy', 'frizzyh', 'frizzyha', 'frizzyhai', 'frizzyhair', 'frogbugging', 'fromizzy', 'fstubborn', 'ftruggling', 'fubb', 'fubbs', 'fubj', 'fuch', 'fuchs', 'fugg', 'fuggi', 'fuggin', 'fuggir', 'fuggit', 'fuggl', 'fuggli', 'fuggly', 'fullplugg', 'fullswung', 'fumbl', 'fumbling', 'fuzz', 'fuzzb', 'fuzzba', 'fuzzbal', 'fuzzball', 'fuzzbu', 'fuzzbuck', 'fuzzbus', 'fuzzbust', 'fuzzbusting', 'fuzzy', 'fuzzyh', 'fuzzywuzz', 'fuzzywuzzi', 'fuzzywuzzy', 'fuzzywuzzys', 'fwizzl', 'fzzzzz', 'g', 'gang', 'gangbang', 'ganging', 'ganglyshrugg', 'gangp', 'gangpl', 'gangpla', 'gangplan', 'gangplank', 'gangw', 'gangwa', 'gangway', 'gasguzzl', 'ggggh', 'ghangh', 'ghangha', 'ghanghar', 'ghostlywhit', 'giftfluffy', 'girlalmostcatatonicwithjoy', 'girlclutching', 'gizz', 'gizza', 'gizzar', 'gizzard', 'gizzardg', 'gizzardgu', 'gizzardgul', 'gizzardgulp', 'gizzardgulping', 'gizzy', 'gizzz', 'gizzzy', 'gizzzzzy', 'glaringlywhit', 'glubb', 'glubbi', 'glubbin', 'glubbing', 'glugg', 'glugging', 'gluggy', 'glumb', 'glumby', 'gngh', 'goddaught', 'gojush', 'gojusho', 'gojushor', 'gong', 'gongbanging', 'gormathrong', 'gough', 'granddaught', 'grayfuzz', 'grazza', 'grazzan', 'grazzano', 'griffith', 'grippythings', 'grizz', 'grizzk', 'grizzka', 'grizzl', 'grizzly', 'grouch', 'grouching', 'grouchy', 'grouphugging', 'grubb', 'grubbish', 'grubby', 'gruffy', 'grumbl', 'grumbling', 'guardstumbling', 'gubb', 'gubbi', 'gubbig', 'gubbin', 'gubbins', 'guff', 'guffa', 'guffah', 'guffaw', 'gugg', 'gumb', 'gumba', 'gumbal', 'gumball', 'gumballs', 'gumban', 'gumband', 'gumbands', 'gumbi', 'gumbo', 'gumby', 'gumrubb', 'gungswizzl', 'gushing', 'gutrumbl', 'gutrumbli', 'gutrumblin', 'gutrumbling', 'guyscrubb', 'guyscrubbi', 'guyscrubbin', 'guyscrubbing', 'guzz', 'guzzi', 'guzzl', 'guzzling', 'gypzzz', 'h', 'haaargghhh', 'haauugggh', 'haauugh', 'haiphong', 'hajjar', 'hajji', 'halfbubbl', 'halfciviliz', 'halfcough', 'halfcrashing', 'halfcrouch', 'halfcrouching', 'halfcrumbl', 'halfcrumbli', 'halfcrumblin', 'halfcrumbling', 'halfdistraught', 'halfdraught', 'halfdrugg', 'halfflung', 'halfhanging', 'halfjoyful', 'halflaugh', 'halflaughing', 'halfliz', 'halfliza', 'halflizar', 'halflizard', 'halfmumbl', 'halfmumbling', 'halfpushing', 'halfpuzzl', 'halfquizzical', 'halfrubb', 'halfshrugg', 'halfslumb', 'halfsplashing', 'halfstrangl', 'halfstumbl', 'halfstumbling', 'halfsubj', 'halfthought', 'halfthoughtful', 'halftumbl', 'halfwishing', 'handcuff', 'handcuffs', 'hang', 'hanging', 'haphazz', 'haphazza', 'haphazzar', 'haphazzard', 'haphazzardl', 'haphazzardly', 'happywhich', 'hardfought', 'hardfoughtfor', 'harjorxas', 'hartblumb', 'hatching', 'haught', 'haughti', 'haughtil', 'haughtily', 'haughtin', 'haughty', 'hauugggh', 'hauuggghh', 'hauugh', 'hauuugggh', 'hhaghh', 'hiccough', 'hiccoughing', 'high', 'highb', 'highba', 'highback', 'highbad', 'highbal', 'highball', 'highballing', 'highban', 'highbank', 'highbo', 'highbom', 'highboy', 'highbr', 'highbrow', 'highbu', 'highbud', 'highbudg', 'highbur', 'highbury', 'highbut', 'highbutt', 'highbutto', 'highbutton', 'highbuzzing', 'highflung', 'highhigh', 'highhighn', 'highju', 'highjud', 'highjudg', 'highjum', 'highjump', 'highlystyliz', 'highw', 'highwa', 'highwai', 'highwais', 'highwaist', 'highwal', 'highwall', 'highwat', 'highwav', 'highway', 'highwi', 'highwin', 'highwind', 'highwindow', 'highwinds', 'highwing', 'highwir', 'highwo', 'highwou', 'highwoul', 'highwould', 'himapologiz', 'himhanging', 'himstumbling', 'hiphugg', 'hiphugging', 'hizz', 'hngh', 'hough', 'houghm', 'houghma', 'houghmag', 'houghmaga', 'houghmagan', 'houghmagand', 'houghmagandy', 'houghmagandying', 'houghs', 'hruuugh', 'hubb', 'hubba', 'hubbahubb', 'hubbahubba', 'hubbar', 'hubbard', 'hubbi', 'hubbl', 'hubbu', 'hubbub', 'hubby', 'huff', 'huffing', 'hugg', 'huggghhh', 'hugging', 'hugginghow', 'hugh', 'humanssubjugat', 'humbl', 'humbly', 'humbug', 'humburg', 'humong', 'humongo', 'humongou', 'humongous', 'hung', 'hunghang', 'hunghung', 'hushing', 'huuuuuurrrrrrgggggghhhh', 'huzz', 'huzza', 'huzzah', 'huzzai', 'huzzain', 'huzzaing', 'huzzz', 'i', 'idahowashington', 'idoliz', 'if', 'ifanything', 'ijj', 'ijja', 'ijjan', 'ijju', 'ikillanythingthatb', 'ikillanythingthatbr', 'iknowjusthowyouf', 'illthought', 'illwishing', 'imbliz', 'imblizi', 'imblizid', 'imblizidl', 'imblizidly', 'immobiliz', 'incumb', 'ingh', 'ingha', 'inghar', 'ingharr', 'injur', 'injury', 'intothqw', 'irong', 'ironga', 'irongat', 'irongau', 'irongaun', 'irongaunt', 'irongauntl', 'irongr', 'irongra', 'irongrat', 'irongray', 'itfumbl', 'itsughw', 'ittoqq', 'ittoqqo', 'ittoqqor', 'ittoqqort', 'ittoqqorto', 'ittoqqortoo', 'ittoqqortoor', 'ittoqqortoorm', 'ittoqqortoormi', 'ittoqqortoormit', 'ittoqqortoormitt', 'ivbrought', 'izz', 'izza', 'izzat', 'izzay', 'izzayi', 'izzayik', 'izzi', 'izzu', 'izzum', 'izzums', 'izzut', 'izzy', 'izzyalthough', 'j', 'jacqui', 'jacquil', 'jacquili', 'jacquilin', 'jacuzzi', 'jang', 'jangl', 'jangling', 'jango', 'jazz', 'jigsawpuzzl', 'jizz', 'jjju', 'jjjus', 'jjjust', 'jjoh', 'jjohn', 'jobhanging', 'jobjust', 'jong', 'joybuzz', 'ju', 'jub', 'jubi', 'jubil', 'jubila', 'jubilan', 'jubilanc', 'jubilant', 'jubilat', 'jubilati', 'jubilatio', 'jubilation', 'jud', 'judg', 'judging', 'judgm', 'judith', 'jug', 'jugg', 'juggl', 'juggling', 'jugh', 'jugju', 'jugjug', 'jugu', 'jugua', 'juguan', 'jugul', 'jugula', 'jugular', 'jugulat', 'jugulu', 'jugulum', 'jugur', 'jugurth', 'jugurtha', 'jugurthi', 'jugurthia', 'jugurthian', 'juj', 'juji', 'jujis', 'jujist', 'jujistu', 'jujit', 'jujits', 'jujitsu', 'juju', 'jujub', 'jul', 'juli', 'julung', 'julungg', 'julunggu', 'julunggul', 'july', 'julywh', 'julywha', 'julywhat', 'jum', 'juma', 'juman', 'jumanj', 'jumanja', 'jumar', 'jumaring', 'jumars', 'jumb', 'jumbl', 'jumbo', 'jumh', 'jumha', 'jumo', 'jumon', 'jumonv', 'jumonvi', 'jumonvil', 'jumonvill', 'jump', 'jumping', 'jumpingj', 'jumpingja', 'jumpingjack', 'jumpingjacks', 'jumpju', 'jumpjum', 'jumpjump', 'jung', 'jungl', 'jungw', 'jungwh', 'jungwha', 'jungwhan', 'juong', 'juongs', 'jurang', 'jurangp', 'jurangpa', 'jurangpat', 'jurangpati', 'jus', 'jush', 'jusht', 'jushu', 'jusj', 'jusju', 'jusjus', 'just', 'justanything', 'justcrazywhat', 'justgrouch', 'justgrouchy', 'justjus', 'justjust', 'justjustw', 'justjustwa', 'justjustwat', 'justjustwatc', 'justjustwatch', 'justjustwatchi', 'justjustwatchin', 'justjustwatching', 'justwrong', 'k', 'kang', 'kanga', 'kangap', 'kangapa', 'kangapak', 'kangar', 'kangaro', 'kangaroo', 'kangch', 'kavanaugh', 'khang', 'khumbu', 'kiddishthought', 'kijang', 'killjoy', 'kimbrough', 'kjur', 'kjurt', 'knowanywh', 'knowfought', 'knowhang', 'kong', 'konjur', 'konjuro', 'konjuror', 'kouch', 'krissrissizz', 'krissrissizza', 'ktrang', 'kuch', 'kuchch', 'kuchcha', 'kuching', 'kumb', 'kumba', 'kumbay', 'kumbaya', 'kumbayf', 'kumbayfking', 'kumbayfkingy', 'kumbayfkingya', 'kumbu', 'kumbuth', 'l', 'lachulung', 'ladybugh', 'lagriffiths', 'lambslaught', 'lamprubbing', 'landgrubbi', 'landgrubbin', 'landgrubbing', 'landlubb', 'lang', 'langu', 'langua', 'languag', 'langui', 'languid', 'languidl', 'languidly', 'languish', 'languishing', 'larouch', 'lashing', 'latching', 'laugh', 'laughchang', 'laughing', 'laughinglaughing', 'laughingthrough', 'laughingthrought', 'lavishing', 'lawwrong', 'lbj', 'ligh', 'lighd', 'lighdy', 'lighs', 'lighst', 'lighstp', 'light', 'lighth', 'lightho', 'lighthoo', 'lighthoos', 'lighthor', 'lighthors', 'lighthou', 'lighthour', 'lighthours', 'lighthous', 'lightmuch', 'lightnumb', 'lightthough', 'lighv', 'lighvo', 'lighvoo', 'lighvoor', 'lilywhit', 'linishing', 'liz', 'lizz', 'lizzi', 'lizzy', 'lokchang', 'long', 'longjoh', 'longjohn', 'longjohns', 'longmuzzl', 'longrang', 'longslumb', 'longsought', 'loqw', 'loqwa', 'loradawdaught', 'lotmumbling', 'louch', 'louchy', 'lough', 'lowhanging', 'lowhung', 'lowslung', 'lubb', 'luckobj', 'lugg', 'lugga', 'luggag', 'lugging', 'lugh', 'lumb', 'lung', 'lungf', 'lungfi', 'lungfil', 'lungfill', 'lungfilling', 'lungfu', 'lungful', 'lunging', 'lungrumbli', 'lungrumblin', 'lungrumbling', 'lungs', 'luqx', 'lushing', 'lygh', 'lyght', 'lymaugh', 'm', 'mablung', 'maghul', 'magicbuzzi', 'magicbuzzin', 'magicbuzzing', 'mahjong', 'major', 'malijongg', 'mang', 'mangh', 'manghu', 'manghuh', 'manghuhu', 'manghuhul', 'manghuhula', 'manghuhulay', 'manghuhulayo', 'manghuhulayou', 'mangl', 'mango', 'mangobb', 'mangobbl', 'mangobbling', 'mangy', 'manmatching', 'manslaught', 'manywh', 'manywho', 'marjor', 'marjora', 'marjoram', 'marjori', 'marjory', 'matching', 'maugh', 'maugha', 'maugham', 'mazz', 'mazzuch', 'mcbuzzk', 'mcbuzzki', 'mcbuzzkil', 'mcbuzzkill', 'mcguffy', 'mclaugh', 'mclaughl', 'mclaughla', 'mclaughlan', 'mclaughli', 'mclaughlin', 'mclough', 'mcloughl', 'mcloughli', 'mcloughlin', 'mcnaught', 'mcnugg', 'mcqui', 'mcquil', 'mcquilk', 'mcquilki', 'mcquilkin', 'mcquill', 'mcquilli', 'mcquillin', 'mcquin', 'mcquinn', 'mfugg', 'midstruggl', 'migh', 'might', 'milkywhit', 'mindhumbling', 'mindnumbing', 'mistyjungl', 'mizz', 'mizzl', 'mizzli', 'mizzlin', 'mizzling', 'mmmmnngh', 'mobiliz', 'mockapologiz', 'mollywhom', 'moltsstruggl', 'mong', 'mongo', 'mongol', 'mongols', 'mongom', 'mongomo', 'mongoo', 'mongoos', 'mongr', 'monopoliz', 'mostlywhit', 'mounttumbling', 'mouthbrushing', 'mouthwashingmo', 'mouthwashingmor', 'movingchompingscratching', 'mubang', 'mubanga', 'mubb', 'mubbo', 'much', 'muchjust', 'muchstrong', 'muchthumb', 'muchwishing', 'muff', 'muffi', 'muffin', 'muffl', 'muffy', 'mugg', 'mugging', 'muggy', 'mugh', 'mughl', 'mughla', 'mughlai', 'mumb', 'mumba', 'mumbai', 'mumbak', 'mumbaki', 'mumbju', 'mumbjum', 'mumbjumb', 'mumbjumbo', 'mumbl', 'mumbling', 'mumbo', 'mumbojumbo', 'mummydaught', 'murghul', 'murghuli', 'murphywh', 'murphywha', 'murphywhat', 'mushing', 'mustvanquish', 'muthafugg', 'muthafugga', 'muthafuggas', 'muzz', 'muzzi', 'muzzil', 'muzzily', 'muzzl', 'muzzy', 'muzzyh', 'mythicallywhat', 'mythologiz', 'n', 'nanobotjungl', 'naugh', 'naught', 'naughty', 'naughtynaught', 'naughtynaughty', 'nauuughty', 'navrongo', 'ngbj', 'ngorongo', 'ngorongor', 'ngorongoro', 'nigh', 'night', 'nightadjust', 'nightalthough', 'nightclubb', 'nightclubbi', 'nightclubbin', 'nightclubbing', 'nightmuch', 'nightthough', 'nightthrough', 'nightwrough', 'nightwrought', 'nizzb', 'nizzba', 'nizzbar', 'njor', 'njord', 'njus', 'nngh', 'nnngghhh', 'nnngh', 'no', 'nob', 'nobb', 'nobbl', 'nobbly', 'nobblyb', 'nobblybi', 'nobblybit', 'nobblybits', 'nobbs', 'nobbu', 'nobbut', 'nobby', 'nobi', 'nobia', 'nobiar', 'nobiarc', 'nobiarch', 'nobig', 'nobigd', 'nobil', 'nobili', 'nobilis', 'nobilit', 'nobiliti', 'nobility', 'nobilitymuch', 'nobilitythough', 'nobilitywh', 'nobilitywhi', 'nobilitywhich', 'nobilitywhy', 'nobilu', 'nobilus', 'nobir', 'nobird', 'nobirdb', 'nobirdbo', 'nobirdbod', 'nobirdbody', 'nobis', 'nobl', 'nobo', 'nobod', 'nobodi', 'nobody', 'noby', 'nojacklaugh', 'nonfluffy', 'noninjur', 'nonmatching', 'norborough', 'normallywhat', 'northumb', 'norumb', 'nosizzl', 'not', 'noth', 'nothi', 'nothin', 'nothing', 'nothingfjor', 'nothingfjord', 'nothingjust', 'nothingmuch', 'nothip', 'nothis', 'nothish', 'nothough', 'noththing', 'nothung', 'notmuch', 'notmuchb', 'notouch', 'notouching', 'notouchinga', 'notouchingan', 'notouchingany', 'notouchinganyo', 'notouchinganyon', 'notouchy', 'notpuzzl', 'notsohumbl', 'nottouch', 'notwashing', 'nough', 'nought', 'now', 'nowcrumbl', 'nowh', 'nowjoy', 'nowjust', 'nowmuch', 'nownumb', 'nowrubb', 'nowrubbl', 'nowthoroughly', 'nowthoroughlyt', 'nowthoroughlyto', 'nowthoroughlytor', 'nowthoroughlytorn', 'nowtough', 'nozz', 'nozza', 'nozzal', 'nozzala', 'nozzalaw', 'nozzalawh', 'nozzalawhi', 'nozzalawhic', 'nozzalawhich', 'nozzi', 'nozzl', 'nozzy', 'nrrrggghh', 'nubb', 'nubbi', 'nubbin', 'nubbl', 'nubbly', 'nubby', 'nugg', 'numb', 'nuzz', 'nuzzl', 'nuzzling', 'nygh', 'nyght', 'nynngh', 'o', 'ob', 'obj', 'obl', 'obla', 'oblad', 'oblak', 'oblat', 'oblati', 'oblatio', 'oblation', 'obli', 'oblig', 'obliga', 'obligac', 'obligaci', 'obligacio', 'obligacion', 'obligat', 'obligati', 'obligatio', 'obligation', 'obligato', 'obligator', 'obligators', 'obligatorswh', 'obligatorswho', 'obligatory', 'obligay', 'obliging', 'obligingl', 'obligingly', 'oblij', 'obliqu', 'oblis', 'oblit', 'obliv', 'oblivi', 'oblivia', 'oblivian', 'oblivians', 'oblivio', 'oblivion', 'oblivionwh', 'oblivionwhi', 'oblivionwhich', 'obliviou', 'oblivious', 'obliviouscough', 'oblo', 'oblon', 'oblong', 'oblongsh', 'oblongsha', 'oblongshap', 'obloqu', 'obloquy', 'obs', 'obsc', 'obscu', 'obscur', 'obscuring', 'obugg', 'obv', 'obvi', 'obvio', 'obviou', 'obvious', 'obviousl', 'obviousli', 'obviouslik', 'obviouslo', 'obviousloo', 'obviouslook', 'obviouslooki', 'obviouslookin', 'obviouslooking', 'obviously', 'obviout', 'obviouth', 'oc', 'occ', 'occa', 'occam', 'occams', 'occas', 'occasi', 'occasio', 'occasion', 'occasiona', 'occasional', 'occasionall', 'occasionally', 'occasionan', 'occasionand', 'occass', 'occassi', 'occassio', 'occassion', 'occassiona', 'occassional', 'occassionall', 'occassionally', 'occi', 'occid', 'occil', 'occili', 'occilia', 'occilian', 'occilo', 'occilox', 'occip', 'occipi', 'occipit', 'occipita', 'occipital', 'occl', 'occlu', 'occlud', 'occluding', 'occlus', 'occlusi', 'occlusio', 'occlusion', 'occu', 'occul', 'occult', 'occulti', 'occultis', 'occultist', 'occup', 'occupa', 'occupan', 'occupanc', 'occupancy', 'occupant', 'occupants', 'occupat', 'occupati', 'occupatio', 'occupation', 'occupationwh', 'occupi', 'occupy', 'occupying', 'occur', 'occurr', 'occurring', 'occy', 'occyo', 'occyou', 'occyoup', 'occyoupa', 'occyoupay', 'occyoupaysh', 'occyoupayshu', 'occyoupayshun', 'occyoupayshuna', 'occyoupayshunal', 'occyoupayshunall', 'odonnaugh', 'of', 'off', 'offlaugh', 'offlaughing', 'ofotfjord', 'ofstumbl', 'ofstumbli', 'ofstumblin', 'ofstumbling', 'og', 'ogg', 'oggh', 'oggha', 'oggham', 'ogh', 'ognough', 'ognought', 'ogr', 'oh', 'ohpzzzzzzzzzz', 'ohsojoyful', 'oj', 'oji', 'ojib', 'ojibw', 'ojis', 'ojisa', 'ojisan', 'ok', 'oka', 'okaa', 'okaaa', 'okaaaa', 'okaaaaa', 'okaaaaaa', 'okaaaaaaa', 'okaaaaaaaa', 'okaaaaaaaay', 'okaaaaaay', 'okaaaay', 'okaaay', 'okaas', 'okaasa', 'okaasan', 'okaay', 'okaayy', 'okaayyy', 'okah', 'okap', 'okapi', 'okapis', 'okash', 'okasho', 'okashon', 'okashona', 'okashonal', 'okashonall', 'okashonally', 'okav', 'okava', 'okavang', 'okavango', 'okay', 'okayjoh', 'okayjohn', 'okayjust', 'okaythough', 'okaywh', 'okaz', 'okaza', 'okazak', 'okazaki', 'okjo', 'okjock', 'okjust', 'ol', 'old', 'oldmuch', 'oldthough', 'oli', 'olib', 'oliba', 'oliban', 'olibanu', 'olibanum', 'olif', 'olifa', 'olifan', 'olifant', 'olifants', 'olig', 'oliga', 'oligar', 'oligarch', 'oligarchs', 'oligarchy', 'olin', 'olink', 'olinka', 'olip', 'oliph', 'olipha', 'oliphan', 'oliphant', 'oliphants', 'oliphau', 'oliphaun', 'oliphaunt', 'oliphaunts', 'olish', 'oliv', 'olivi', 'olivia', 'olix', 'olv', 'oly', 'olya', 'olym', 'olymp', 'olympi', 'olympia', 'olympian', 'olympic', 'olympics', 'olympicsiz', 'olympu', 'olympus', 'on', 'onfought', 'onlywh', 'onlywha', 'onlywhat', 'onlywho', 'onrushing', 'onslaught', 'onsubj', 'onything', 'oohhbugg', 'oooooooooopppppppppppppppzzzzzzzzzzzzz', 'op', 'opp', 'oppo', 'oppon', 'oppor', 'opport', 'opportu', 'opportun', 'opportuni', 'opportunis', 'opportunism', 'opportunist', 'opportunit', 'opportuniti', 'opportunity', 'opportunitythough', 'opportuniz', 'opportunizi', 'opportunizin', 'opportunizing', 'oppos', 'opposi', 'opposin', 'opposing', 'opposit', 'oppr', 'or', 'orang', 'orcdraught', 'orph', 'orpha', 'orphan', 'orphang', 'oth', 'ou', 'oub', 'oubl', 'oubla', 'oublas', 'oubli', 'ouc', 'ouch', 'ouchqu', 'ouchqui', 'ouchquit', 'oug', 'ougg', 'ouggg', 'ougggh', 'ouggghh', 'ouggghhh', 'ough', 'ought', 'ouh', 'ouhh', 'oui', 'ouij', 'ouija', 'oun', 'ounc', 'ound', 'our', 'ourhumbl', 'ous', 'oust', 'ousting', 'out', 'outflung', 'outfough', 'outfought', 'outmatching', 'outnumb', 'outstubb', 'outstubbo', 'outstubbor', 'outstubborn', 'outthought', 'ouz', 'ouzo', 'ov', 'ow', 'own', 'owuff', 'ox', 'oxb', 'oxbl', 'oxblo', 'oxbloo', 'oxblood', 'oxbow', 'oxbr', 'oxbu', 'oxbut', 'oxbutt', 'oxf', 'oxfa', 'oxfac', 'oxfam', 'oxfi', 'oxfo', 'oxfor', 'oxford', 'oxfordsh', 'oxfordshi', 'oxfordshir', 'oxy', 'oxyc', 'oxyco', 'oxycod', 'oxycodo', 'oxycodon', 'oxycon', 'oxycont', 'oxyconti', 'oxycontin', 'oxycontinc', 'oxycontinco', 'oxycontincod', 'oxycontincodd', 'oxycontincoddl', 'oxyg', 'oxym', 'oxymo', 'oxymor', 'oxymoro', 'oxymoron', 'oz', 'ozz', 'ozzi', 'ozzy', 'ozzzzz', 'p', 'pacqui', 'pacquia', 'pacquiao', 'pajor', 'pajora', 'pang', 'pangb', 'pangbo', 'pangbor', 'pangborn', 'pangj', 'pangja', 'pangjac', 'panglungsod', 'pangong', 'pangongt', 'pangongts', 'pangongtso', 'pantscuffs', 'papapaparazzi', 'paparazzi', 'paparazzo', 'paralogiz', 'partycrashing', 'pastizzi', 'patching', 'patpong', 'pbj', 'pffff', 'pfffff', 'pffffffffff', 'pffffffffffffffff', 'pfffffffffffffffft', 'pfffffffffft', 'pffffft', 'pfffft', 'ph', 'phang', 'phi', 'phia', 'phial', 'phil', 'phili', 'philib', 'philip', 'philipp', 'philippa', 'philippi', 'philippia', 'philippian', 'philippiana', 'philippianau', 'philippianaus', 'philippianaust', 'philippianaustr', 'philippianaustra', 'philippianaustral', 'philippianaustrali', 'philippianaustralia', 'philippianaustralian', 'philippians', 'philippin', 'philis', 'philist', 'philista', 'philisti', 'philistia', 'philistin', 'phill', 'philla', 'phillau', 'phillaus', 'phillauss', 'phillaussi', 'philli', 'phillip', 'philliph', 'phillipp', 'phillis', 'phillm', 'phillmo', 'phillmor', 'phillp', 'phillpo', 'phillpot', 'phillpots', 'philly', 'philo', 'philob', 'philobo', 'philobos', 'philobosi', 'philobosia', 'philobosian', 'philod', 'philol', 'philolo', 'philolog', 'philologi', 'philologic', 'philologica', 'philological', 'philologis', 'philologist', 'philology', 'philos', 'philoso', 'philosoph', 'philosophi', 'philosophic', 'philosophica', 'philosophical', 'philosophiz', 'philosophizing', 'philosophy', 'philoth', 'phipp', 'phipps', 'phish', 'phishizzl', 'phit', 'phits', 'phiz', 'phizz', 'phizzw', 'phizzwhizz', 'phizzwhizzi', 'phizzwhizzin', 'phizzwhizzing', 'phizzwi', 'phizzwiz', 'phizzwiza', 'phizzwizar', 'phizzwizard', 'phizzwizards', 'pho', 'phob', 'phobi', 'phobia', 'phobic', 'phobo', 'phoboph', 'phobopha', 'phobophag', 'phobos', 'phobot', 'phoboto', 'phobotor', 'phobotory', 'phon', 'phot', 'photo', 'photog', 'photogr', 'photogra', 'photograph', 'photogrph', 'photojo', 'photojou', 'photojour', 'photojourn', 'photojourna', 'photojournal', 'photojournali', 'photojournalis', 'photojournalist', 'photosh', 'photosho', 'photoshoo', 'photoshoot', 'photoshop', 'photoshopp', 'photoshopping', 'photoshu', 'photoshum', 'photoshumm', 'photoshummm', 'phott', 'photty', 'phottyg', 'phottygr', 'phottygra', 'phottygraph', 'photu', 'photum', 'photuma', 'photus', 'phy', 'phyf', 'phyl', 'phyla', 'phylac', 'phylact', 'phyll', 'phylli', 'phyllid', 'phyllida', 'phyllidi', 'phyllidia', 'phyllis', 'phyllit', 'phylu', 'phylum', 'phyn', 'phynd', 'phyndy', 'phyndyr', 'phyr', 'phyra', 'phyro', 'phyros', 'phyrr', 'phyrri', 'phyrric', 'phys', 'physc', 'physci', 'physcia', 'physcial', 'physciall', 'physcially', 'physi', 'physic', 'physica', 'physical', 'physici', 'physicia', 'physician', 'physicis', 'physicist', 'physick', 'physics', 'physik', 'physio', 'physiog', 'physiogn', 'physiogno', 'physiognom', 'physiognomi', 'physiognomic', 'physiognomis', 'physiognomist', 'physiognomy', 'physiol', 'physiolo', 'physiolog', 'physiologi', 'physiologic', 'physiologica', 'physiological', 'physiologis', 'physiologist', 'physiology', 'physioth', 'physiqu', 'pigslaught', 'pingpong', 'pinkywhit', 'pizazz', 'pizz', 'pizza', 'pizzaj', 'pizzaji', 'pizzajit', 'pizzajits', 'pizzajitsu', 'pizzajo', 'pizzajoi', 'pizzajoin', 'pizzajoint', 'pizzazz', 'planksrumbl', 'plashing', 'plasticuffs', 'platinumblond', 'playdough', 'playfought', 'plaything', 'plough', 'ploughb', 'ploughbo', 'ploughboy', 'ploughing', 'ploughsh', 'ploughsha', 'ploughshar', 'plugg', 'plugging', 'plugh', 'plugho', 'plughol', 'plumb', 'plumbi', 'plumbin', 'plumbing', 'plumbingalthough', 'plumbl', 'plumbla', 'plumblack', 'plumbli', 'plumblin', 'plung', 'plunging', 'pogswizzl', 'poisonwishing', 'polishing', 'poliz', 'polizi', 'polizia', 'polizn', 'polizna', 'poliznay', 'poliznaya', 'pologiz', 'poooooofffff', 'postpizza', 'pouch', 'pough', 'poughk', 'prizzl', 'prizzzz', 'probablywh', 'prong', 'prongh', 'prongho', 'pronghor', 'pronghorn', 'prongs', 'pubb', 'publishing', 'puff', 'puffbang', 'puffbangs', 'puffing', 'puffingwh', 'puffy', 'puffywuffy', 'puggl', 'pugh', 'pullingugh', 'push', 'pushing', 'pussywhip', 'pussywhipp', 'puzz', 'puzzl', 'q', 'qju', 'qqq', 'qu', 'quantumfuzz', 'quashing', 'qui', 'quick', 'quickl', 'quickli', 'quicklik', 'quicklim', 'quicklin', 'quickling', 'quickliv', 'quickll', 'quicklln', 'quickllng', 'quicklo', 'quickloa', 'quickload', 'quickloo', 'quicklook', 'quicklooki', 'quicklookin', 'quicklooking', 'quickly', 'quicklymuch', 'quicklythough', 'quickmuch', 'quizz', 'quizzi', 'quizzic', 'quizzica', 'quizzical', 'quizzicall', 'quizzically', 'quizzin', 'quizzing', 'qv', 'qvc', 'qw', 'r', 'raaaaaaarrrrrrrgggghhhhhhhh', 'raaargghhhhhhhhhhhh', 'raghuvir', 'raiththought', 'rajang', 'rakoczywhy', 'ralphjust', 'rang', 'rankmajor', 'ravishing', 'razz', 'razza', 'razzaq', 'razztwizzl', 'rhumb', 'ribcrushing', 'ribjo', 'ribjoi', 'ribjoin', 'ribjoint', 'ridcuffy', 'righ', 'right', 'righthugg', 'rightpizz', 'rightpizza', 'rightthrough', 'riiiiiigggghhh', 'riiiiiigggghhht', 'rizz', 'rizzo', 'rnuzz', 'rnuzzi', 'rnuzzil', 'rnuzzily', 'rocksmashing', 'rocktumbl', 'rocktumbli', 'rocktumblin', 'rocktumbling', 'rongong', 'rongongy', 'rongongyu', 'rongongyul', 'rongongyula', 'rongongyulas', 'rough', 'roughandtumbl', 'roughh', 'roughshing', 'roughshingl', 'rozzy', 'rrrang', 'rubb', 'rubbing', 'rubbish', 'ruff', 'ruffi', 'ruffia', 'ruffian', 'ruffians', 'ruffl', 'ruffling', 'rugg', 'rumb', 'rumbl', 'rumbling', 'rumbu', 'rumbus', 'rumbust', 'rumbusti', 'rumbustio', 'rumbustiou', 'rumbustious', 'rumbustiousn', 'rush', 'rushing', 'rushjob', 's', 'saluzzo', 'sang', 'sarabhanga', 'sarong', 'saught', 'saughto', 'saughton', 'sayizzy', 'scarborough', 'schaumburg', 'scratching', 'scrdfngh', 'scrubb', 'scrubbing', 'scrubbush', 'scrubby', 'scruffy', 'scruffyh', 'scruffyha', 'scruffyhai', 'scruffyhair', 'scrumbl', 'scubb', 'scubbo', 'scuff', 'scuffing', 'scuffl', 'scuffling', 'scugg', 'scuggi', 'scuggin', 'scuggins', 'scumb', 'scumba', 'scumbag', 'scumbl', 'scumbu', 'scumbuck', 'scuzz', 'scuzzb', 'scuzzba', 'scuzzbal', 'scuzzball', 'scuzzy', 'scything', 'sh', 'shadowhung', 'shallowdraught', 'sharong', 'shirttugging', 'shizz', 'shocktumbl', 'shopbought', 'shortrang', 'shotguninjur', 'shotrang', 'show', 'showing', 'shrubb', 'shrubby', 'shrugg', 'shtrang', 'shtrong', 'shtuff', 'shubb', 'shuff', 'shuffing', 'shuffl', 'shuffling', 'shushing', 'sigh', 'sightjust', 'sinkplung', 'siquijor', 'sirjurg', 'siz', 'sizzl', 'sizzling', 'skazz', 'skinnyflashing', 'skrong', 'skugg', 'skugga', 'skuggab', 'skuggaba', 'skuggabal', 'skuggabald', 'skuggabaldu', 'skuggabaldur', 'skuldugg', 'skulldugg', 'skuzz', 'skuzzi', 'skuzzy', 'skydaught', 'skyghu', 'skyghua', 'skyghuar', 'skywhit', 'slanging', 'slapsplashing', 'slashing', 'slaught', 'slidstumbl', 'slightlywhy', 'sloaaaaaaaauughh', 'slouch', 'slouching', 'slough', 'sloughing', 'slugg', 'sluggi', 'sluggin', 'slugging', 'sluggis', 'sluggish', 'slugh', 'slugho', 'slughor', 'slughorn', 'slumb', 'slung', 'slushing', 'smashing', 'smugg', 'smugging', 'smuggl', 'smuggling', 'smushing', 'snaahhghhh', 'snatching', 'snowjob', 'snowplough', 'snowywhit', 'snozzcumb', 'snubb', 'snubbing', 'snuffy', 'snugg', 'snugging', 'snuggl', 'snuggling', 'snuzz', 'snuzzl', 'soapbubbl', 'song', 'songhigh', 'songjust', 'sorghum', 'sorghump', 'sorghumpo', 'sorghumpor', 'sorghumporr', 'sorghumporri', 'sorghumporrid', 'sorghumporridg', 'souchong', 'sough', 'soughing', 'sought', 'soughtsought', 'sourdough', 'spazz', 'spazzing', 'splashing', 'splishing', 'splishings', 'splishsplashing', 'spong', 'spongy', 'sprang', 'squ', 'squashing', 'squish', 'squishing', 'squishsquishsquish', 'squishy', 'squizzl', 'squizzly', 'ssstrongh', 'ssstrongho', 'ssstronghol', 'ssstronghold', 'staatspoliz', 'stabiliz', 'starsthoroughly', 'stickatnaught', 'stickluggin', 'stillcrouching', 'stillhanging', 'stillsizzling', 'stillsluggish', 'stillstruggling', 'stomachlizards', 'strang', 'straphanging', 'straumfjord', 'stringsubj', 'strong', 'strongh', 'strongho', 'stronghol', 'stronghold', 'stronghon', 'stronghono', 'strongstrong', 'strucksmashing', 'struggl', 'struggling', 'stubb', 'stubbing', 'stubbish', 'stubbl', 'stubbo', 'stubbor', 'stubborn', 'stubbornthough', 'stubby', 'stuff', 'stuffjust', 'stumbl', 'stumbling', 'stungthough', 'stupidgrubbs', 'styliz', 'styrbjor', 'styrbjorn', 'subb', 'subba', 'subban', 'subbank', 'subbanks', 'subbas', 'subbing', 'subby', 'subbys', 'subbyst', 'subbystr', 'subbystra', 'subbystrai', 'subbystraig', 'subbystraigh', 'subbystraight', 'subciviliz', 'subciviliza', 'subcivilizat', 'subcivilizati', 'subcivilizatio', 'subcivilization', 'subj', 'subsubb', 'subsubba', 'subsubbas', 'succumb', 'succumbing', 'such', 'suff', 'sugg', 'sumong', 'sunlightjust', 'suzz', 'suzzi', 'swishing', 'swizz', 'swizzf', 'swizzfi', 'swizzfig', 'swizzfigg', 'swizzfiggl', 'swizzfiggli', 'swizzfigglin', 'swizzfiggling', 'swizzl', 'swung', 'symboliz', 't', 'tabith', 'tabitha', 'tailofthought', 'tang', 'tanging', 'tangl', 'tanglang', 'tanjung', 'tankardclanging', 'taqw', 'taqwa', 'taugh', 'taught', 'th', 'thatching', 'thcrubb', 'thigh', 'thighb', 'thighbi', 'thighbit', 'thighbo', 'thighbon', 'thighboo', 'thighboot', 'thighboots', 'thighhigh', 'thighs', 'thighwh', 'thighwhy', 'thingslaught', 'thingsugg', 'thinkthrough', 'thirtyaughtsix', 'thorough', 'thoroughb', 'thoroughbr', 'thoroughf', 'thoroughfa', 'thoroughfar', 'thoroughl', 'thoroughly', 'thoroughlyobj', 'though', 'thoughchang', 'thoughjust', 'thought', 'thoughthough', 'thoughthought', 'thoughthoughts', 'thoughtnumbing', 'thoughtthought', 'thqw', 'thrashing', 'throng', 'through', 'throughstrong', 'thtrang', 'thtrong', 'thtrongi', 'thtrongin', 'thtronginth', 'thtuff', 'thubj', 'thugg', 'thuggi', 'thuggish', 'thumb', 'thumbl', 'thumbthrough', 'thwough', 'tiff', 'tiffa', 'tiffan', 'tiffany', 'tiffy', 'tight', 'tightjust', 'tightywh', 'tightywhi', 'tightywhit', 'tightywhiti', 'tiljus', 'tipsybugg', 'tiriumbutor', 'tiriumbutora', 'tizzl', 'tizzy', 'to', 'toizzy', 'tong', 'tongo', 'tongs', 'tongu', 'toosugg', 'toothbrushing', 'topsugg', 'torbjor', 'torbjorn', 'torbjorns', 'torizzz', 'torumbu', 'torumbur', 'tothqw', 'touch', 'touching', 'tough', 'toughtough', 'tqw', 'tqwa', 'tqwan', 'tqwana', 'trabjo', 'tranquiliz', 'tranquilliz', 'trashing', 'traught', 'trong', 'trongs', 'trongsa', 'trough', 'tryshrugg', 'tubb', 'tubbing', 'tubby', 'tuckborough', 'tuffy', 'tugg', 'tuggatuggatugg', 'tuggatuggatugga', 'tuggatuggatuggat', 'tuggatuggatuggatu', 'tuggatuggatuggatug', 'tuggatuggatuggatugg', 'tuggatuggatuggatugga', 'tuggatuggatuggatuggat', 'tuggatuggatuggatuggatu', 'tuggatuggatuggatuggatug', 'tugging', 'tugh', 'tughl', 'tughlu', 'tughluq', 'tumb', 'tumba', 'tumbal', 'tumbar', 'tumbas', 'tumbl', 'tumbling', 'tumbr', 'tumbri', 'tumbril', 'tw', 'twang', 'twanging', 'twi', 'twib', 'twibi', 'twibil', 'twibill', 'twic', 'twick', 'twid', 'twidd', 'twiddl', 'twiddling', 'twidl', 'twif', 'twig', 'twigg', 'twigging', 'twiggy', 'twigs', 'twih', 'twiha', 'twihar', 'twihard', 'twil', 'twilight', 'twim', 'twin', 'twing', 'twinjo', 'twinjoi', 'twinjoin', 'twink', 'twinki', 'twinkl', 'twinkling', 'twinprong', 'twipp', 'twippp', 'twir', 'twiri', 'twirig', 'twirk', 'twirks', 'twirl', 'twirling', 'twirp', 'twirpy', 'twis', 'twist', 'twisting', 'twit', 'twitch', 'twitching', 'twith', 'twitt', 'twittish', 'twix', 'twixt', 'twiz', 'twizzl', 'twizzling', 'two', 'twoprong', 'twostubb', 'twostubbi', 'twowatching', 'u', 'ubj', 'ug', 'uga', 'ugab', 'ugan', 'ugana', 'uganaw', 'uganawu', 'ugand', 'uganda', 'ugandan', 'ugggghhhh', 'ugggh', 'uggghh', 'uggghhh', 'uggghhhh', 'uggh', 'ugghh', 'ugh', 'ughh', 'ughhh', 'ughugh', 'ughughugh', 'ugl', 'ugli', 'uglo', 'ugloi', 'ugloid', 'ugloids', 'uglu', 'ugluk', 'ugly', 'ugurghhhhh', 'uh', 'uhgh', 'uhghb', 'uhghbd', 'uhghbdu', 'uhghbduh', 'uhh', 'uhhh', 'uhhhh', 'uhhhhgg', 'uhhhhgggg', 'uhhhhggggg', 'uhhhhh', 'uhhhhhh', 'uhhhwh', 'uhhhwha', 'uhhhwhaa', 'uhhj', 'uhhjj', 'uhhu', 'uhhuh', 'uhhum', 'uhhun', 'uhhunh', 'uhjust', 'ujung', 'umb', 'umbi', 'umbil', 'umbili', 'umbilic', 'umbilica', 'umbilical', 'umbilicu', 'umbilicus', 'umbr', 'un', 'unbraught', 'unbraughto', 'unbraughton', 'unbraughtonl', 'unbraughtonli', 'unbraughtonlik', 'uncaught', 'unchang', 'unchanging', 'unciviliz', 'unclutching', 'uncough', 'uncrouch', 'uncuff', 'uncuffing', 'undiminishing', 'unf', 'unfa', 'unfac', 'unfad', 'unfading', 'unfag', 'unfagn', 'unfai', 'unfail', 'unfailing', 'unfailingl', 'unfailingly', 'unfair', 'unfaith', 'unfaithf', 'unfaithfu', 'unfaithful', 'unfak', 'unfal', 'unfall', 'unfalo', 'unfalon', 'unfalonl', 'unfalonli', 'unfalonlik', 'unfalt', 'unfam', 'unfami', 'unfamil', 'unfamila', 'unfamilar', 'unfamili', 'unfamilia', 'unfamiliar', 'unfan', 'unfanc', 'unfanci', 'unfancia', 'unfanciab', 'unfanciabl', 'unfar', 'unfarm', 'unfas', 'unfash', 'unfashi', 'unfashio', 'unfashion', 'unfashiona', 'unfashionab', 'unfashionabl', 'unfast', 'unfat', 'unfath', 'unfatho', 'unfathom', 'unfathoma', 'unfathomab', 'unfathomabi', 'unfathomabil', 'unfathomabili', 'unfathomabilit', 'unfathomability', 'unfathomabl', 'unfati', 'unfatig', 'unfatigu', 'unfav', 'unfavo', 'unfavor', 'unfavora', 'unfavorab', 'unfavorabl', 'unfavorably', 'unfavori', 'unfavorit', 'unfavou', 'unfavour', 'unfavoura', 'unfavourab', 'unfavourabl', 'unfavourably', 'unfaz', 'unfi', 'unfig', 'unfigu', 'unfigur', 'unfil', 'unfill', 'unfilt', 'unfin', 'unfind', 'unfinda', 'unfindab', 'unfindabl', 'unfini', 'unfinish', 'unfir', 'unfit', 'unfix', 'unflung', 'unfo', 'unfoc', 'unfocu', 'unfocus', 'unfol', 'unfold', 'unfolding', 'unfoll', 'unfollow', 'unfon', 'unfond', 'unfont', 'unfoo', 'unfool', 'unfoola', 'unfoolab', 'unfoolabl', 'unfor', 'unforg', 'unforgi', 'unforgiv', 'unforgiva', 'unforgivab', 'unforgivabl', 'unforgiving', 'unform', 'unfort', 'unforti', 'unfortif', 'unfortifi', 'unfortu', 'unfortun', 'unfortuna', 'unfortunat', 'unfou', 'unfough', 'unfought', 'unfoul', 'unfoun', 'unfound', 'unfraught', 'unfu', 'unfuck', 'unfucking', 'unfuckingb', 'unful', 'unfulf', 'unfulfi', 'unfulfil', 'unfulfill', 'unfulfilling', 'unfun', 'unfund', 'unfunk', 'unfunn', 'unfunny', 'unfur', 'unfurl', 'unfurling', 'unfurn', 'unfurni', 'unfurnish', 'unfurr', 'unfurrow', 'unfus', 'unfuss', 'unfuzz', 'ung', 'unggh', 'ungu', 'ungua', 'unguar', 'unguard', 'ungui', 'unguid', 'ungul', 'ungula', 'ungulan', 'ungulant', 'ungulat', 'unh', 'unhang', 'unhumbl', 'uninjur', 'unjust', 'unlashing', 'unlatching', 'unngghh', 'unngh', 'unnngh', 'unnumb', 'unobj', 'unplough', 'unplugg', 'unplugging', 'unplumb', 'unqu', 'unrubb', 'unslung', 'unsought', 'unsugg', 'untabith', 'untabitha', 'untaught', 'unthought', 'unthoughtf', 'unthoughtfu', 'unthoughtful', 'untouch', 'untough', 'unutiliz', 'unvanquish', 'unvanquisha', 'unvanquishab', 'unvanquishabl', 'unwashing', 'unwashingt', 'unwashingto', 'unwashington', 'unwrough', 'unwrought', 'up', 'upanything', 'upchang', 'updraught', 'upflung', 'uprushing', 'upthought', 'urggghhh', 'urgghh', 'urghh', 'urghhg', 'urghhgr', 'urghhgrr', 'urghhu', 'urghhur', 'urghhurh', 'urrgghh', 'urrgghhi', 'us', 'ush', 'uslaughing', 'usthought', 'uswatching', 'utiliz', 'uufghh', 'uugghhw', 'uugh', 'uuuggghhh', 'uuugghh', 'uuuugh', 'uzz', 'v', 'vajazzl', 'vang', 'vanga', 'vangau', 'vangaur', 'vangaurd', 'vangaurds', 'vangh', 'vangl', 'vangu', 'vangua', 'vanguar', 'vanguard', 'vanquish', 'vanquishing', 'vaugh', 'vaugha', 'vaughan', 'vaughn', 'vigh', 'vigho', 'vighol', 'vigholf', 'vikjor', 'vikjord', 'vinillaquishio', 'vouch', 'w', 'waaarggghh', 'waithubby', 'walkanywh', 'walkingstumblingtoward', 'walkthrough', 'walkthroughw', 'walkthroughwa', 'walkthroughwal', 'walkthroughwall', 'walkthroughwalls', 'wallhanging', 'wammalugh', 'warmandfuzzy', 'wasfizzl', 'washing', 'watching', 'waugh', 'waxilliumbut', 'waxywhit', 'wayizzy', 'wazz', 'wazziz', 'wazzizn', 'wazzizna', 'wazziznai', 'wazziznaim', 'wh', 'whackjob', 'whatcouldgowrong', 'whatiswrongwithm', 'whinnylaugh', 'whinylaugh', 'whiplashing', 'whizbang', 'whizz', 'whizzing', 'whizzp', 'whizzpo', 'whizzpopp', 'whizzpopping', 'whoppsywhiffling', 'whuuugh', 'whuzz', 'whuzza', 'whuzzat', 'whywh', 'whywhy', 'willbjorn', 'willoughby', 'willowboughs', 'willowjungl', 'wiradjuri', 'wish', 'wishing', 'wishthough', 'wishthought', 'wishthoughts', 'with', 'wiz', 'wiza', 'wizar', 'wizard', 'wizbang', 'wizz', 'wizza', 'wizzaa', 'wizzaaa', 'wizzaaar', 'wizzaaard', 'wizzaaards', 'wizzaaardsa', 'wizzaaardsah', 'wizzar', 'wizzard', 'wizzi', 'wizzio', 'wizzip', 'wizzl', 'wizzla', 'wizzy', 'wizzz', 'wizzza', 'wizzzar', 'wizzzard', 'womanslaught', 'woodconjur', 'woodfuzz', 'workdaught', 'workrough', 'worldanythingthat', 'wrang', 'wrangl', 'wrangling', 'wrong', 'wrongjust', 'wrongthough', 'wrough', 'wrought', 'wubb', 'wubbl', 'wuchang', 'wumbl', 'wuthjus', 'wuzz', 'wuzza', 'wuzzas', 'wuzzat', 'wuzzi', 'wuzzin', 'wuzzing', 'wuzzingt', 'wuzzingto', 'wuzzington', 'wuzzingtons', 'wuzzy', 'wuzzys', 'wwwbjw', 'wwwbjwh', 'wwwbjwhi', 'wwwbjwhit', 'wwwbjwhitt', 'wwwbjwhitti', 'wwwbjwhittin', 'wwwbjwhitting', 'wwwbjwhittingt', 'wwwbjwhittingto', 'wwwbjwhittington', 'wwwbjwhittingtonc', 'wwwbjwhittingtonco', 'wwwbjwhittingtoncom', 'wwwdonmcqui', 'wwwdonmcquin', 'wwwdonmcquinn', 'wwwdonmcquinnc', 'wwwdonmcquinnco', 'wwwdonmcquinncom', 'wwwwaarggghh', 'x', 'xchang', 'xh', 'xha', 'xhai', 'xhar', 'xhara', 'xharan', 'xho', 'xhos', 'xhosa', 'xhy', 'xhys', 'xhysh', 'xhysha', 'xith', 'xitha', 'xithar', 'xithari', 'xitharis', 'xithi', 'xithiwh', 'xithiwha', 'xithiwhat', 'xuch', 'xucho', 'xuchot', 'xuchotl', 'xx', 'xxi', 'xxii', 'xxiii', 'xxiv', 'xxix', 'xxv', 'xxvi', 'xxvii', 'xxviii', 'xxx', 'xxxv', 'xxxvi', 'xxxvii', 'xxxviii', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxx', 'xxxxxxxxx', 'xxxxxxxxxx', 'y', 'yaaaagghh', 'yaaghh', 'yaarrghh', 'yajur', 'yajurv', 'yalumba', 'yang', 'yarborough', 'yarbrough', 'yarrrrrrrrrgghhhh', 'yazz', 'yazzi', 'yijja', 'yizzl', 'yizzll', 'yo', 'yog', 'yoga', 'yogh', 'yoghu', 'yoghur', 'yoghurt', 'yogi', 'yogic', 'yogo', 'yogs', 'yogso', 'yogsoth', 'yogsotho', 'yogsothoth', 'yogu', 'yogur', 'yogurt', 'yogw', 'yogwa', 'yogwan', 'yogy', 'yogya', 'yogyak', 'yogyaka', 'yogyakar', 'yogyakart', 'yogyakarta', 'yoh', 'yoha', 'yohan', 'yoho', 'yohoh', 'yohoho', 'yoj', 'yoja', 'yojal', 'yojali', 'yojalin', 'yoji', 'yok', 'yokch', 'yoku', 'yokum', 'yokut', 'yokuts', 'yokutsh', 'yokutshow', 'yokwh', 'yokwha', 'yokwhat', 'yom', 'yong', 'yongb', 'yongbo', 'yongx', 'yongxing', 'yor', 'york', 'yorksh', 'yorksha', 'yorkshad', 'yorkshi', 'yorkshir', 'yosh', 'yoshi', 'yoshim', 'yoshimi', 'yoshimiz', 'yoshimizu', 'yoshimo', 'yoshimu', 'yoshimur', 'yoshimura', 'you', 'youaugh', 'youclangsugg', 'young', 'yow', 'yowch', 'yowl', 'yowling', 'yoww', 'yowz', 'yowza', 'ywung', 'yyyyarrgghhh', 'z', 'zang', 'zanga', 'zangal', 'zangali', 'zangalio', 'zangall', 'zangalli', 'zangallio', 'zazumba', 'zhang', 'zhongq', 'zhongqi', 'zhongqiu', 'zhongqiuj', 'zhongqiuji', 'zippfizz', 'zippfizzi', 'zippfizzin', 'zippfizzing', 'zough', 'ztrong', 'ztrongi', 'ztrongin', 'ztronginz', 'zugg', 'zumb', 'zumba', 'zuzz', 'zuzzi', 'zuzzin', 'zuzzing', 'zzz', 'zzzo', 'zzzol', 'zzzolt', 'zzzoltk', 'zzzoltko', 'zzzoltkol', 'zzzoltkola', 'zzzs', 'zzzt', 'zzzz', 'zzzzp', 'zzzzpp', 'zzzzppp', 'zzzzz', 'zzzzzt', 'zzzzzzz', 'zzzzzzzzzzzzz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate vocabulary (this is the slowest part because the subword splits are merger iteratively)\n",
    "tokenizer.generate_vocab(text, max_vocab_size=8192)\n",
    "print(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb Cell 38\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# test encoding and decoding a sentence\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m s \u001b[39m=\u001b[39m text[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(s)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mtokenize_sentence(s))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# test encoding and decoding a sentence\n",
    "s = text[0]\n",
    "print(s)\n",
    "print(tokenizer.tokenize_sentence(s))\n",
    "encoded = tokenizer.encode([s])\n",
    "print(encoded)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets encode the dataset into integer token sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding sequences.: 100%|██████████| 7993754/7993754 [00:00<00:00, 10383100.01it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_encoded = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save a copy of the trained tokenizer to file\n",
    "'''\n",
    "with open('WordPiece_tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)\n",
    "'''\n",
    "\n",
    "# load tokenizer object from file\n",
    "'''\n",
    "with open('WordPiece_tokenizer.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file) \n",
    "'''\n",
    "\n",
    "# save encoded dataset to file\n",
    "'''\n",
    "with open('dataset_encoded', 'wb') as file:\n",
    "    pickle.dump(dataset_encoded, file)   \n",
    "'''\n",
    "\n",
    "'''\n",
    "with open('dataset_encoded_1M', 'rb') as file:\n",
    "    dataset_encoded = pickle.load(file)\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 3362.88 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num sequences: 1000000\n",
      "Shortest: 0\n",
      "Longest: 1896\n",
      "Average: 46.170686\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [len(s) for s in dataset_encoded] \n",
    "print(f\"Total num sequences: {len(dataset_encoded)}\")\n",
    "print(f\"Shortest: {min(lengths)}\")\n",
    "print(f\"Longest: {max(lengths)}\")\n",
    "print(f\"Average: {sum(lengths)/len(lengths)}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show histrogram of sequence length distribution\n",
    "plt.hist(lengths, bins=128)\n",
    "plt.xlim(0,300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Dataset API for prepping data for Masked Language Model Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, corpus, tokenizer, block_size, mlm_prob=0.15):\n",
    "        self.corpus = corpus          # encoded sentences\n",
    "        self.tokenizer = tokenizer    # wordpiece tokenizer\n",
    "        self.block_size = block_size  # truncation/max length of sentences\n",
    "        self.corpus_len = len(corpus) # size of corpus\n",
    "        self.mlm_prob = mlm_prob\n",
    "        self.vocab_size = tokenizer.vocab_size()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_len\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the sentence \n",
    "        s = self.get_corpus_sentence(idx)\n",
    "        # truncate to block_size-1\n",
    "        s = s[:self.block_size-1] \n",
    "        \n",
    "        s_len = len(s)\n",
    "        # replace tokens randomly\n",
    "        s, label = self.replace_tokens(s)\n",
    "        # append the CLS token at the beginning of sentence\n",
    "        s = [self.tokenizer.cls_token_id()] + s\n",
    "        # apply padding\n",
    "        pad_len = max(0,self.block_size-s_len-1)\n",
    "        s = s + [self.tokenizer.pad_token_id()]*pad_len\n",
    "        label = [-100] + label + [-100]*pad_len\n",
    "        # create attention mask which has 0's at positions of pad tokens and 1's everywhere else \n",
    "        attention_mask = [1]*(self.block_size-pad_len) + [0]*pad_len       \n",
    "\n",
    "        # convert to torch tensors\n",
    "        s = torch.tensor(s)\n",
    "        label = torch.tensor(label)\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "        # Note: Unlike the original BERT, we are not returning a pair of sentences, so we\n",
    "        # don't need to return segment labels or next_sentence label \n",
    "        return {\"masked_input\" : s, \"label\" : label, \"attention_mask\" : attention_mask}\n",
    "\n",
    "\n",
    "    # randomly replace tokens with mlm_prob probability\n",
    "    def replace_tokens(self, s):\n",
    "\n",
    "        # the labels for a masked token is the original token index and -100 for non-masked tokens\n",
    "        label = [-100] * len(s)\n",
    "        for i,t in enumerate(s):\n",
    "            p = random.random()    \n",
    "            if p < self.mlm_prob:\n",
    "                p = p/self.mlm_prob\n",
    "                # replace with masked token with 80% probability\n",
    "                if p < 0.8:\n",
    "                    s[i] = self.tokenizer.mask_token_id()        \n",
    "\n",
    "                elif p < 0.9:\n",
    "                    # replace with random token with 10% probability \n",
    "                    s[i] = random.randrange(self.vocab_size)\n",
    "                \n",
    "                # Note: for all three cases, i.e. token getting replaced by mask token, token getting replaced\n",
    "                # by another random token or token not getting replaced, we want to predict the actual word as our target label \n",
    "                label[i] = t\n",
    "\n",
    "        return s, label\n",
    "\n",
    "\n",
    "    def get_corpus_sentence(self, idx):\n",
    "        return self.corpus[idx]        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader for generating batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 250000\n"
     ]
    }
   ],
   "source": [
    "block_size = 96\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = BERTDataset(dataset_encoded, tokenizer, block_size=block_size)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=1)  # set pin_memory for faster pre-fetching \n",
    "print(f\"Total number of batches: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'masked_input': tensor([[3475, 7277,  768, 3719, 2047, 2784, 2784, 6388,  768, 1846,  768,  657,\n",
       "          7277,  768, 3476, 2047, 3350, 3480, 1846,  657, 3920,    0, 2390, 3476,\n",
       "           769, 3126, 1458, 1458, 3362, 6519, 1133,  578,  768,  657, 3476, 6376,\n",
       "           768, 6249, 7277,  768, 3933, 2047,  533, 2047, 1458,    0, 2938,  768,\n",
       "          2784, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477],\n",
       "         [3475, 7263,    0, 3476, 3476,  657, 3283, 3476, 1846, 2938,    0, 3476,\n",
       "           768, 6249, 7277,  768, 5725,  768, 2390, 6908,  768,    0,  549, 6249,\n",
       "          5220, 1133, 2784, 7851,  768, 3476, 2282, 2047, 3476, 5220,  768, 7851,\n",
       "             0, 2784, 3526,  768, 7351, 5618,  768,  768, 2282, 3480, 2938, 2938,\n",
       "             0,  578,  768, 3476, 2784, 4976, 3476, 2047, 3476, 5106,  768, 2938,\n",
       "          2938, 1254, 3476, 1458, 3476, 3476,  768, 4691, 7351, 3480, 2938, 2938,\n",
       "             0,  578, 3476, 7277, 2094, 1133, 2390, 6987, 3296, 2047, 2390,  657,\n",
       "          2784, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477],\n",
       "         [3475, 7277,  768, 5220, 2047, 1846, 2047, 2390, 6249, 3719,  768, 1254,\n",
       "          4976, 1133, 2390, 2784, 2938, 7851,  768, 3476, 2938, 3476, 7277,  768,\n",
       "          7810, 3990,    0, 2784, 2938, 5106, 3476,    0, 2390,  657, 3719,    0,\n",
       "          2390, 2378, 3476, 7277,  768, 4631,    0,  856, 1458,  768, 3480, 6987,\n",
       "          3476,  768,  768, 1458, 1042, 3126, 1458, 1458,  768,  657, 7823, 3476,\n",
       "          2784, 2784,  768, 1458, 3476, 3480, 3476, 2282,    0, 2390, 2390, 3476,\n",
       "           657, 5662,  768, 1909, 6249, 7277, 2390, 3476,  768, 1042, 3126, 1846,\n",
       "           346, 2390,  768,  657, 4976,  768,  768, 2938, 3480, 1846,  657, 3480],\n",
       "         [3475, 7277,  768, 3476, 3476, 5407, 3476, 6048,  768, 2390,  768, 7277,\n",
       "          3476, 2938, 3476, 3476, 2047, 3126, 1458,  657, 3719,  768, 6987,    0,\n",
       "           769,  768, 4976, 2390, 2047, 1760, 5220, 1133, 1760, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477,\n",
       "          3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477, 3477]]),\n",
       " 'label': tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, 3719, -100, -100, -100, -100, -100, -100, -100, -100,  768,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 7792, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100,    0, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [-100, -100, -100, 1429, 3480, -100, -100,    0, -100, -100, -100,  856,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100,    0, -100, -100, 1846, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, 2390, -100, -100, 2390, -100, 1760, -100, -100, -100,\n",
       "          -100, -100, 3920, -100, 2047, 2784, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, 7909, -100,  768, -100, 2390, 6987, -100, -100, 2390, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, 1846, -100, 7351, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, 3126, -100, -100, -100, -100, -100,\n",
       "          -100, -100,  768, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          2938, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,  768,\n",
       "          -100, -100, -100, -100, 7909, -100, 6987, -100, -100, -100, -100,  768,\n",
       "          -100, -100, -100, -100, -100, -100, -100,  768, -100, -100, -100, -100,\n",
       "           657, -100, -100, -100, -100,  768, -100, -100, -100, 1846, -100, -100],\n",
       "         [-100, -100, -100, 2390,  768, -100, 2784, -100, -100, -100, -100, -100,\n",
       "             0, -100, 5407, 7851, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           769,  768, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]),\n",
       " 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load an example batch and show the contents\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96])\n",
      "torch.Size([32, 96])\n",
      "torch.Size([32, 96])\n"
     ]
    }
   ],
   "source": [
    "print(sample_batch['masked_input'].shape)\n",
    "print(sample_batch['label'].shape)\n",
    "print(sample_batch['attention_mask'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's train our BERT model on the MLM task. Note that were using fixed sized input sequences, denoted by block_size. Ideally we would want block_size to be as large as possible because a larger context window leads to the model learning better language representations from the MLM task. However, there are obvious computational constraints which prevent us from making block_size too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, optimizer, epoch=None, loss=None):\n",
    "    # Save the model and optimizer state_dict\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "\n",
    "    # Save the checkpoint to a file\n",
    "    torch.save(checkpoint, 'BERT_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in transformer network: 20.523776 M\n",
      "RAM used: 5984.86 MB\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 384\n",
    "head_size = embedding_dim\n",
    "num_heads = 12\n",
    "num_blocks = 8\n",
    "dropout_rate = 0.2\n",
    "max_iters = 3\n",
    "learning_rate = 1e-4\n",
    "smoothed_loss = 0.0\n",
    "\n",
    "model = BERTModel(vocab_size=tokenizer.vocab_size(), block_size=block_size, embedding_dim=embedding_dim, head_size=head_size, num_heads=num_heads, num_blocks=num_blocks, pad_token_id=tokenizer.pad_token_id(), dropout_rate=dropout_rate)\n",
    "# move model to device\n",
    "m = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "\n",
    "num_params = sum(p.numel() for p in m.parameters())\n",
    "print(f\"Total number of parameters in transformer network: {num_params/1e6} M\")\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch Loss: 1.006, Moving avg. Loss: 1.178:  19%|█▉        | 12107/62452 [14:42<1:01:08, 13.72it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb Cell 52\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m xb, yb, attn_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mmasked_input\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# move batches to gpu\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m xb \u001b[39m=\u001b[39m xb\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m yb \u001b[39m=\u001b[39m yb\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tanzid/Code/Stanford_Courses/Language_Models/Andrej_Karpathy_Tutorials/transformer_BERT.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m attn_mask \u001b[39m=\u001b[39m attn_mask\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(max_iters):\n",
    "    pbar = tqdm(train_dataloader, desc=\"Epochs\")\n",
    "    for batch in pbar:\n",
    "        # sample a batch of trainin data\n",
    "        xb, yb, attn_mask = batch['masked_input'], batch['label'], batch['attention_mask'] \n",
    "        # move batches to gpu\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        attn_mask = attn_mask.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = m(xb, attn_mask)\n",
    "        # compute loss\n",
    "        B,T,vocab_size = logits.shape\n",
    "        # reshape the logits and targets such that batch of input sequences are flattened into a single big input sequence\n",
    "        # i.e. (B,T) --> (B*T)\n",
    "        logits = logits.view(B*T,vocab_size) # reshaped to (B*T,vocab_size)\n",
    "        yb = yb.view(B*T) # reshaped to (B*T)\n",
    "        # compute cross entropy loss (i.e. average negative log likelihood)\n",
    "        loss = F.cross_entropy(logits, yb, ignore_index=-100)\n",
    "\n",
    "        # exponential moving average loss\n",
    "        smoothed_loss = 0.9 * smoothed_loss + 0.1 * loss.item()\n",
    "\n",
    "        # reset parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True) \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_description(f\"Epoch {epoch + 1}, Batch Loss: {loss:.3f}, Moving avg. Loss: {smoothed_loss:.3f}\")   \n",
    "    \n",
    "    # save checkpoint \n",
    "    save_model_checkpoint(m, optimizer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load the checkpoint from the file\n",
    "checkpoint = torch.load('BERT_checkpoint.pth')\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = BERTModel(vocab_size=tokenizer.vocab_size(), block_size=block_size, embedding_dim=embedding_dim, head_size=head_size, num_heads=num_heads, num_blocks=num_blocks, pad_token_id=tokenizer.pad_token_id(), dropout_rate=dropout_rate)\n",
    "# move model to device\n",
    "m = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "\n",
    "# Load the model and optimizer state_dict from the checkpoint\n",
    "m.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "m.train()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at some test predictions made by our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create test dataset (since first 1M lines are used for training, grab lines from after that point)\n",
    "with open(\"bookcorpus_small.txt\", 'r') as f:\n",
    "    # get 2000 lines\n",
    "    test_lines = list(islice(f, 2000000, 2002000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the sentences\n",
    "for i, s in enumerate(test_lines):\n",
    "    s = test_lines[i].strip()\n",
    "    test_lines[i] = \"\".join(ch for ch in s if unicodedata.category(ch)[0]=='L' or unicodedata.category(ch)=='Zs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
